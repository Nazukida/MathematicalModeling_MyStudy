"""
============================================================
éšæœºæ£®æ—å›å½’ (Random Forest Regression)
é€‚ç”¨äºç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› (MCM/ICM)
============================================================
åŠŸèƒ½ï¼šå¤šå˜é‡å›å½’é¢„æµ‹ã€ç‰¹å¾é‡è¦æ€§åˆ†æã€éçº¿æ€§å…³ç³»å»ºæ¨¡
åŸç†ï¼šé›†æˆå¤šæ£µå›å½’æ ‘ï¼Œå–å¹³å‡å€¼ä½œä¸ºé¢„æµ‹
ä½œè€…ï¼šMCM/ICM Team
============================================================
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# å›¾è¡¨ç¾åŒ–è®¾ç½®
plt.style.use('seaborn-v0_8-whitegrid')
rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False


class RFRegressor:
    """
    éšæœºæ£®æ—å›å½’å™¨å°è£…ç±»
    
    ä¼˜ç‚¹ï¼š
    - æ•æ‰éçº¿æ€§å…³ç³»
    - è‡ªåŠ¨å¤„ç†ç‰¹å¾äº¤äº’
    - è¾“å‡ºç‰¹å¾é‡è¦æ€§
    - æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼º
    
    å‚æ•°è¯´æ˜ï¼š
    - n_estimators: å†³ç­–æ ‘æ•°é‡ï¼ˆ100-500ï¼‰
    - max_depth: æœ€å¤§æ·±åº¦ï¼ˆNoneä¸é™åˆ¶ï¼Œ5-20å¸¸ç”¨ï¼‰
    - min_samples_split: åˆ†è£‚æœ€å°æ ·æœ¬æ•°
    """
    
    def __init__(self, n_estimators=100, max_depth=None, 
                 min_samples_split=2, random_state=42, verbose=True):
        """
        å‚æ•°é…ç½®
        
        :param n_estimators: å†³ç­–æ ‘æ•°é‡
        :param max_depth: æœ€å¤§æ·±åº¦
        :param min_samples_split: æœ€å°åˆ†è£‚æ ·æœ¬æ•°
        """
        self.model = RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            random_state=random_state,
            n_jobs=-1
        )
        self.verbose = verbose
        self.feature_names = None
        self.feature_importance = None
        self.r2 = None
        self.rmse = None
        self.mae = None
        self.y_test = None
        self.y_pred = None
    
    def fit(self, X, y, test_size=0.2):
        """
        è®­ç»ƒæ¨¡å‹
        
        :param X: ç‰¹å¾DataFrameæˆ–æ•°ç»„
        :param y: æ ‡ç­¾
        :param test_size: æµ‹è¯•é›†æ¯”ä¾‹
        """
        if isinstance(X, pd.DataFrame):
            self.feature_names = list(X.columns)
        else:
            self.feature_names = [f"ç‰¹å¾{i+1}" for i in range(X.shape[1])]
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # è®­ç»ƒ
        self.model.fit(X_train, y_train)
        
        # é¢„æµ‹ä¸è¯„ä¼°
        self.y_test = y_test
        self.y_pred = self.model.predict(X_test)
        self.r2 = r2_score(y_test, self.y_pred)
        self.rmse = np.sqrt(mean_squared_error(y_test, self.y_pred))
        self.mae = mean_absolute_error(y_test, self.y_pred)
        
        # ç‰¹å¾é‡è¦æ€§
        self.feature_importance = pd.Series(
            self.model.feature_importances_,
            index=self.feature_names
        ).sort_values(ascending=False)
        
        if self.verbose:
            self._print_results()
        
        return self
    
    def _print_results(self):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*50)
        print("ğŸŒ² éšæœºæ£®æ—å›å½’ç»“æœ")
        print("="*50)
        print(f"\n  RÂ² å¾—åˆ†: {self.r2:.4f}")
        print(f"  RMSE: {self.rmse:.4f}")
        print(f"  MAE: {self.mae:.4f}")
        print(f"\n  ç‰¹å¾é‡è¦æ€§:")
        for name, imp in self.feature_importance.items():
            bar = "â–ˆ" * int(imp * 30)
            print(f"    {name}: {imp:.4f} {bar}")
        print("="*50)
    
    def cross_validate(self, X, y, cv=5):
        """äº¤å‰éªŒè¯"""
        scores = cross_val_score(self.model, X, y, cv=cv, scoring='r2')
        print(f"\näº¤å‰éªŒè¯ (cv={cv}):")
        print(f"  RÂ² å¾—åˆ†: {scores.mean():.4f} Â± {scores.std():.4f}")
        print(f"  å„æŠ˜å¾—åˆ†: {scores.round(4)}")
        return scores
    
    def predict(self, X):
        """é¢„æµ‹"""
        return self.model.predict(X)
    
    def plot_feature_importance(self, save_path=None):
        """å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§"""
        if self.feature_importance is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨fit()è®­ç»ƒæ¨¡å‹")
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        importance = self.feature_importance.sort_values(ascending=True)
        colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(importance)))
        
        bars = ax.barh(importance.index, importance.values, color=colors,
                      edgecolor='white', linewidth=2)
        
        ax.set_xlabel('é‡è¦æ€§', fontsize=12, fontweight='bold')
        ax.set_title('éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§ï¼ˆå›å½’ï¼‰', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='x')
        
        for bar, val in zip(bars, importance.values):
            ax.text(val + 0.01, bar.get_y() + bar.get_height()/2,
                   f'{val:.4f}', va='center', fontsize=10)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_prediction(self, save_path=None):
        """å¯è§†åŒ–é¢„æµ‹ vs çœŸå®"""
        if self.y_test is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨fit()è®­ç»ƒæ¨¡å‹")
        
        fig, ax = plt.subplots(figsize=(8, 8))
        
        ax.scatter(self.y_test, self.y_pred, alpha=0.6, 
                  color='#2E86AB', edgecolor='white', s=60)
        
        # ç†æƒ³çº¿
        lims = [min(self.y_test.min(), self.y_pred.min()),
                max(self.y_test.max(), self.y_pred.max())]
        ax.plot(lims, lims, 'r--', linewidth=2, label='ç†æƒ³é¢„æµ‹çº¿')
        
        ax.set_xlabel('çœŸå®å€¼', fontsize=12, fontweight='bold')
        ax.set_ylabel('é¢„æµ‹å€¼', fontsize=12, fontweight='bold')
        ax.set_title(f'é¢„æµ‹ vs çœŸå® (RÂ²={self.r2:.4f})', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()


# ============================================================
# ç¤ºä¾‹è¿è¡Œ
# ============================================================
if __name__ == "__main__":
    
    print("\n" + "="*60)
    print("   éšæœºæ£®æ—å›å½’æ¼”ç¤º - é”€é‡é¢„æµ‹")
    print("="*60)
    
    # 1. æ¨¡æ‹Ÿæ•°æ®ï¼ˆé”€é‡ä¸å¹¿å‘ŠæŠ•å…¥ã€å®¢æµé‡çš„å…³ç³»ï¼‰
    np.random.seed(42)
    n_samples = 200
    ad_spend = np.random.uniform(10, 100, n_samples)
    traffic = np.random.uniform(500, 2000, n_samples)
    # éçº¿æ€§å…³ç³»
    sales = 5 + 0.3*ad_spend + 0.01*traffic + 0.001*ad_spend*traffic/10 + np.random.normal(0, 2, n_samples)
    
    data = pd.DataFrame({
        "å¹¿å‘ŠæŠ•å…¥": ad_spend,
        "å®¢æµé‡": traffic,
        "é”€é‡": sales
    })
    
    print("\næ•°æ®æ¦‚è§ˆï¼š")
    print(data.describe().round(2))
    
    # 2. è®­ç»ƒæ¨¡å‹
    X = data[["å¹¿å‘ŠæŠ•å…¥", "å®¢æµé‡"]]
    y = data["é”€é‡"]
    
    rf = RFRegressor(n_estimators=100, max_depth=10, verbose=True)
    rf.fit(X, y, test_size=0.2)
    
    # 3. äº¤å‰éªŒè¯
    rf.cross_validate(X, y, cv=5)
    
    # 4. å¯è§†åŒ–
    rf.plot_feature_importance()
    rf.plot_prediction()
    
    # 5. æ–°æ ·æœ¬é¢„æµ‹
    new_data = pd.DataFrame({
        "å¹¿å‘ŠæŠ•å…¥": [50, 80],
        "å®¢æµé‡": [1000, 1500]
    })
    predictions = rf.predict(new_data)
    print(f"\næ–°æ ·æœ¬é¢„æµ‹é”€é‡: {predictions.round(2)}")
