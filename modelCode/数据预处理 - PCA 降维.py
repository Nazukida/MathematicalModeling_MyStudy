"""
============================================================
PCA ä¸»æˆåˆ†åˆ†æé™ç»´ (Principal Component Analysis)
é€‚ç”¨äºç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› (MCM/ICM)
============================================================
åŠŸèƒ½ï¼šé«˜ç»´æ•°æ®é™ç»´ã€ç‰¹å¾æå–ã€æ•°æ®å¯è§†åŒ–ã€å»é™¤å†—ä½™
åŸç†ï¼šå¯»æ‰¾æ–¹å·®æœ€å¤§çš„æŠ•å½±æ–¹å‘
ä½œè€…ï¼šMCM/ICM Team
============================================================
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# å›¾è¡¨ç¾åŒ–è®¾ç½®
plt.style.use('seaborn-v0_8-whitegrid')
rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False


class PCAReducer:
    """
    PCAé™ç»´å°è£…ç±»
    
    æ ¸å¿ƒåŸç†ï¼š
    1. æ•°æ®æ ‡å‡†åŒ–ï¼ˆé›¶å‡å€¼ï¼Œå•ä½æ–¹å·®ï¼‰
    2. è®¡ç®—åæ–¹å·®çŸ©é˜µ
    3. æ±‚ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
    4. é€‰å–å‰kä¸ªä¸»æˆåˆ†
    
    åº”ç”¨åœºæ™¯ï¼š
    - é«˜ç»´æ•°æ®å¯è§†åŒ–ï¼ˆé™åˆ°2D/3Dï¼‰
    - å»é™¤ç‰¹å¾é—´çš„å…±çº¿æ€§
    - é™ä½è®¡ç®—å¤æ‚åº¦
    - æ•°æ®å‹ç¼©
    """
    
    def __init__(self, n_components=None, variance_threshold=0.85, verbose=True):
        """
        å‚æ•°é…ç½®
        
        :param n_components: ä¿ç•™çš„ä¸»æˆåˆ†æ•°ï¼ˆNoneè‡ªåŠ¨é€‰æ‹©ï¼‰
        :param variance_threshold: è‡ªåŠ¨é€‰æ‹©æ—¶çš„æ–¹å·®é˜ˆå€¼
        :param verbose: æ˜¯å¦æ‰“å°è¿‡ç¨‹
        """
        self.n_components = n_components
        self.variance_threshold = variance_threshold
        self.verbose = verbose
        
        self.scaler = StandardScaler()
        self.pca = None
        self.explained_variance = None
        self.cumulative_variance = None
        self.components = None
        self.feature_names = None
        self.n_selected = None
    
    def fit_transform(self, X):
        """
        æ‹Ÿåˆå¹¶è½¬æ¢æ•°æ®
        
        :param X: åŸå§‹æ•°æ®ï¼ˆDataFrameæˆ–æ•°ç»„ï¼‰
        :return: é™ç»´åçš„æ•°æ®
        """
        if isinstance(X, pd.DataFrame):
            self.feature_names = list(X.columns)
        else:
            self.feature_names = [f"ç‰¹å¾{i+1}" for i in range(X.shape[1])]
        
        # æ ‡å‡†åŒ–
        X_std = self.scaler.fit_transform(X)
        
        # æ‹ŸåˆPCA
        self.pca = PCA()
        pca_result = self.pca.fit_transform(X_std)
        
        # è®¡ç®—æ–¹å·®è´¡çŒ®
        self.explained_variance = self.pca.explained_variance_ratio_
        self.cumulative_variance = np.cumsum(self.explained_variance)
        self.components = self.pca.components_
        
        # ç¡®å®šä¿ç•™çš„ä¸»æˆåˆ†æ•°
        if self.n_components is None:
            self.n_selected = np.argmax(self.cumulative_variance >= self.variance_threshold) + 1
        else:
            self.n_selected = self.n_components
        
        if self.verbose:
            self._print_results(X)
        
        return pca_result[:, :self.n_selected]
    
    def _print_results(self, X):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*50)
        print("ğŸ“Š PCA ä¸»æˆåˆ†åˆ†æç»“æœ")
        print("="*50)
        print(f"\n  åŸå§‹ç»´åº¦: {X.shape[1]}")
        print(f"  ä¿ç•™ä¸»æˆåˆ†: {self.n_selected}")
        print(f"  æ–¹å·®é˜ˆå€¼: {self.variance_threshold*100:.0f}%")
        print(f"\n  å„ä¸»æˆåˆ†æ–¹å·®è´¡çŒ®:")
        for i, (var, cum) in enumerate(zip(self.explained_variance, self.cumulative_variance)):
            bar = "â–ˆ" * int(var * 30)
            print(f"    PC{i+1}: {var:.4f} (ç´¯è®¡: {cum:.4f}) {bar}")
            if i >= self.n_selected - 1:
                break
        print(f"\n  é™ç»´åç»´åº¦: {self.n_selected}")
        print(f"  ä¿ç•™ä¿¡æ¯é‡: {self.cumulative_variance[self.n_selected-1]*100:.1f}%")
        print("="*50)
    
    def get_loadings(self):
        """è·å–ä¸»æˆåˆ†è½½è·ï¼ˆå„ç‰¹å¾å¯¹ä¸»æˆåˆ†çš„è´¡çŒ®ï¼‰"""
        loadings = pd.DataFrame(
            self.components[:self.n_selected].T,
            index=self.feature_names,
            columns=[f"PC{i+1}" for i in range(self.n_selected)]
        )
        return loadings
    
    def plot_variance(self, save_path=None):
        """å¯è§†åŒ–æ–¹å·®è´¡çŒ®"""
        if self.explained_variance is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨fit_transform()")
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        n = len(self.explained_variance)
        x = np.arange(1, n + 1)
        
        # æŸ±çŠ¶å›¾
        bars = ax.bar(x, self.explained_variance, color='#2E86AB', 
                     edgecolor='white', linewidth=2, alpha=0.8, label='å•ä¸ªæ–¹å·®è´¡çŒ®')
        
        # ç´¯è®¡æ›²çº¿
        ax.plot(x, self.cumulative_variance, 'o-', color='#E94F37', 
               linewidth=2.5, markersize=8, label='ç´¯è®¡æ–¹å·®')
        
        # é˜ˆå€¼çº¿
        ax.axhline(y=self.variance_threshold, color='green', linestyle='--',
                  linewidth=2, label=f'é˜ˆå€¼ ({self.variance_threshold*100:.0f}%)')
        
        # æ ‡è®°é€‰æ‹©ç‚¹
        ax.axvline(x=self.n_selected, color='orange', linestyle=':',
                  linewidth=2, label=f'é€‰æ‹© {self.n_selected} ä¸ªä¸»æˆåˆ†')
        
        ax.set_xlabel('ä¸»æˆåˆ†', fontsize=12, fontweight='bold')
        ax.set_ylabel('æ–¹å·®è´¡çŒ®æ¯”', fontsize=12, fontweight='bold')
        ax.set_title('PCA æ–¹å·®è´¡çŒ®åˆ†æ', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.legend(loc='center right', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_2d(self, X, y=None, save_path=None):
        """2Dæ•£ç‚¹å›¾å¯è§†åŒ–"""
        X_pca = self.fit_transform(X)
        
        if X_pca.shape[1] < 2:
            print("éœ€è¦è‡³å°‘2ä¸ªä¸»æˆåˆ†æ‰èƒ½ç»˜åˆ¶2Då›¾")
            return
        
        fig, ax = plt.subplots(figsize=(10, 8))
        
        if y is not None:
            scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, 
                               cmap='viridis', s=60, alpha=0.7, edgecolor='white')
            plt.colorbar(scatter, ax=ax, label='ç±»åˆ«')
        else:
            ax.scatter(X_pca[:, 0], X_pca[:, 1], color='#2E86AB',
                      s=60, alpha=0.7, edgecolor='white')
        
        ax.set_xlabel(f'PC1 ({self.explained_variance[0]*100:.1f}%)', 
                     fontsize=12, fontweight='bold')
        ax.set_ylabel(f'PC2 ({self.explained_variance[1]*100:.1f}%)',
                     fontsize=12, fontweight='bold')
        ax.set_title('PCA 2D æŠ•å½±', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()


# ============================================================
# ç¤ºä¾‹è¿è¡Œ
# ============================================================
if __name__ == "__main__":
    
    print("\n" + "="*60)
    print("   PCA ä¸»æˆåˆ†åˆ†ææ¼”ç¤º")
    print("="*60)
    
    # 1. ç”Ÿæˆé«˜ç»´æ•°æ®ï¼ˆ5ä¸ªç‰¹å¾ï¼Œå«ç›¸å…³æ€§ï¼‰
    np.random.seed(42)
    n = 200
    feature1 = np.random.normal(0, 1, n)
    feature2 = 0.8*feature1 + np.random.normal(0, 0.5, n)  # ä¸feature1ç›¸å…³
    feature3 = 0.7*feature1 + 0.2*feature2 + np.random.normal(0, 0.4, n)
    feature4 = np.random.normal(1, 1, n)  # ç‹¬ç«‹ç‰¹å¾
    feature5 = 0.6*feature4 + np.random.normal(0, 0.6, n)
    
    data = pd.DataFrame({
        "f1": feature1, "f2": feature2, "f3": feature3, 
        "f4": feature4, "f5": feature5
    })
    
    print("\nåŸå§‹æ•°æ®æ¦‚è§ˆï¼š")
    print(data.describe().round(2))
    
    # 2. PCAé™ç»´
    pca = PCAReducer(variance_threshold=0.85, verbose=True)
    data_reduced = pca.fit_transform(data)
    
    print(f"\né™ç»´åæ•°æ®å½¢çŠ¶: {data_reduced.shape}")
    
    # 3. ä¸»æˆåˆ†è½½è·
    loadings = pca.get_loadings()
    print("\nä¸»æˆåˆ†è½½è·ï¼ˆå„ç‰¹å¾å¯¹ä¸»æˆåˆ†çš„è´¡çŒ®ï¼‰ï¼š")
    print(loadings.round(4))
    
    # 4. å¯è§†åŒ–
    pca.plot_variance()
    
    # 5. å¸¦æ ‡ç­¾çš„2Då¯è§†åŒ–
    labels = np.random.choice([0, 1, 2], n)  # æ¨¡æ‹Ÿç±»åˆ«æ ‡ç­¾
    pca.plot_2d(data, y=labels)
