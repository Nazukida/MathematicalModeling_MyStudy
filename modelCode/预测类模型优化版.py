"""
============================================================
é¢„æµ‹ç±»æ¨¡å‹ (Prediction Models)
åŒ…å«ï¼šæ—¶é—´åºåˆ— + å›å½’æ¨¡å‹ + æœºå™¨å­¦ä¹ é¢„æµ‹
é€‚ç”¨äºç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› (MCM/ICM)
============================================================
åŠŸèƒ½ï¼šæ—¶é—´åºåˆ—é¢„æµ‹ã€å›å½’åˆ†æã€è¶‹åŠ¿é¢„æµ‹
ç‰¹ç‚¹ï¼šå®Œæ•´çš„å‚æ•°è®¾ç½®ã€æ•°æ®é¢„å¤„ç†ã€å¯è§†åŒ–ä¸ç¾åŒ–
ä½œè€…ï¼šMCM/ICM Team
æ—¥æœŸï¼š2026å¹´1æœˆ
============================================================

ä½¿ç”¨åœºæ™¯ï¼š
- é”€é‡/å®¢æµé‡/è‚¡ä»·é¢„æµ‹
- è¶‹åŠ¿åˆ†æä¸å¤–æ¨
- å¤šå˜é‡å›å½’é¢„æµ‹
- æ—¶é—´åºåˆ—åˆ†è§£ä¸é¢„æµ‹
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
import warnings
from datetime import datetime, timedelta
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso

warnings.filterwarnings('ignore')


# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå…¨å±€é…ç½®ä¸ç¾åŒ–è®¾ç½® (Global Configuration)
# ============================================================

class PlotStyleConfig:
    """å›¾è¡¨ç¾åŒ–é…ç½®ç±» - ç¬¦åˆå­¦æœ¯è®ºæ–‡æ ‡å‡†"""
    
    COLORS = {
        'primary': '#2E86AB',
        'secondary': '#A23B72',
        'accent': '#F18F01',
        'success': '#C73E1D',
        'neutral': '#3B3B3B',
        'background': '#FAFAFA',
        'actual': '#2E86AB',
        'predicted': '#C73E1D',
        'confidence': '#F18F01'
    }
    
    PALETTE = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6B4C9A', '#1B998B']
    
    @staticmethod
    def setup_style():
        plt.style.use('seaborn-v0_8-whitegrid')
        rcParams['figure.figsize'] = (12, 8)
        rcParams['figure.dpi'] = 100
        rcParams['savefig.dpi'] = 300
        rcParams['font.size'] = 11
        rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        rcParams['axes.unicode_minus'] = False

PlotStyleConfig.setup_style()


# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆå™¨ (Time Series Generator)
# ============================================================

class TimeSeriesGenerator:
    """æ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆå™¨ - ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    
    def __init__(self, random_seed=42):
        self.random_seed = random_seed
        np.random.seed(random_seed)
    
    def generate_trend_seasonal(self, n_periods=365, 
                                 trend_type='linear',
                                 seasonal_period=7,
                                 noise_level=10):
        """
        ç”Ÿæˆå¸¦è¶‹åŠ¿å’Œå­£èŠ‚æ€§çš„æ—¶é—´åºåˆ—
        
        :param n_periods: æ•°æ®ç‚¹æ•°é‡
        :param trend_type: è¶‹åŠ¿ç±»å‹ ('linear', 'quadratic', 'exponential')
        :param seasonal_period: å­£èŠ‚å‘¨æœŸ
        :param noise_level: å™ªå£°æ°´å¹³
        """
        t = np.arange(n_periods)
        
        # è¶‹åŠ¿æˆåˆ†
        if trend_type == 'linear':
            trend = 100 + 0.5 * t
        elif trend_type == 'quadratic':
            trend = 100 + 0.01 * t**2
        elif trend_type == 'exponential':
            trend = 100 * np.exp(0.005 * t)
        
        # å­£èŠ‚æ€§æˆåˆ†
        seasonal = 20 * np.sin(2 * np.pi * t / seasonal_period)
        
        # å™ªå£°
        noise = np.random.normal(0, noise_level, n_periods)
        
        # åˆæˆ
        y = trend + seasonal + noise
        
        dates = pd.date_range(start='2024-01-01', periods=n_periods, freq='D')
        
        return pd.DataFrame({
            'date': dates,
            'value': y,
            'trend': trend,
            'seasonal': seasonal,
            'noise': noise
        })
    
    def generate_arima_like(self, n_periods=200, ar_coefs=[0.7], ma_coefs=[0.3]):
        """ç”ŸæˆARIMAé£æ ¼çš„æ—¶é—´åºåˆ—"""
        np.random.seed(self.random_seed)
        
        y = np.zeros(n_periods)
        errors = np.random.normal(0, 1, n_periods)
        
        p = len(ar_coefs)
        q = len(ma_coefs)
        
        for t in range(max(p, q), n_periods):
            ar_term = sum(ar_coefs[i] * y[t-i-1] for i in range(p))
            ma_term = sum(ma_coefs[i] * errors[t-i-1] for i in range(q))
            y[t] = ar_term + ma_term + errors[t]
        
        y = y + 100  # å¹³ç§»
        dates = pd.date_range(start='2024-01-01', periods=n_periods, freq='D')
        
        return pd.DataFrame({'date': dates, 'value': y})
    
    def generate_multivariate(self, n_samples=200):
        """ç”Ÿæˆå¤šå˜é‡å›å½’æ•°æ®"""
        np.random.seed(self.random_seed)
        
        # è‡ªå˜é‡
        X1 = np.random.uniform(10, 100, n_samples)  # å¹¿å‘ŠæŠ•å…¥
        X2 = np.random.uniform(500, 2000, n_samples)  # å®¢æµé‡
        X3 = np.random.randint(1, 6, n_samples)  # ä¿ƒé”€åŠ›åº¦
        
        # å› å˜é‡ï¼ˆæœ‰å™ªå£°çš„çº¿æ€§å…³ç³»ï¼‰
        y = 5 + 0.3 * X1 + 0.01 * X2 + 2 * X3 + np.random.normal(0, 3, n_samples)
        
        return pd.DataFrame({
            'å¹¿å‘ŠæŠ•å…¥': X1,
            'å®¢æµé‡': X2,
            'ä¿ƒé”€åŠ›åº¦': X3,
            'é”€é‡': y
        })


# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ—¶é—´åºåˆ—åˆ†æ (Time Series Analysis)
# ============================================================

class TimeSeriesAnalyzer:
    """æ—¶é—´åºåˆ—åˆ†æç±»"""
    
    def __init__(self, data, date_col='date', value_col='value'):
        """
        åˆå§‹åŒ–
        :param data: DataFrameæˆ–Series
        :param date_col: æ—¥æœŸåˆ—å
        :param value_col: å€¼åˆ—å
        """
        if isinstance(data, pd.DataFrame):
            self.dates = pd.to_datetime(data[date_col])
            self.values = data[value_col].values
        else:
            self.dates = data.index
            self.values = data.values
        
        self.n = len(self.values)
        self.decomposition = None
    
    def moving_average(self, window=7):
        """
        ç§»åŠ¨å¹³å‡
        :param window: çª—å£å¤§å°
        :return: ç§»åŠ¨å¹³å‡åºåˆ—
        """
        return pd.Series(self.values).rolling(window=window, center=True).mean().values
    
    def exponential_smoothing(self, alpha=0.3):
        """
        ç®€å•æŒ‡æ•°å¹³æ»‘
        :param alpha: å¹³æ»‘ç³»æ•° (0-1)
        :return: å¹³æ»‘åçš„åºåˆ—
        """
        smoothed = np.zeros(self.n)
        smoothed[0] = self.values[0]
        
        for t in range(1, self.n):
            smoothed[t] = alpha * self.values[t] + (1 - alpha) * smoothed[t-1]
        
        return smoothed
    
    def holt_winters(self, alpha=0.3, beta=0.1, gamma=0.1, 
                     seasonal_period=7, n_forecast=30):
        """
        Holt-Wintersä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘ï¼ˆåŠ æ³•æ¨¡å‹ï¼‰
        
        :param alpha: æ°´å¹³å¹³æ»‘ç³»æ•°
        :param beta: è¶‹åŠ¿å¹³æ»‘ç³»æ•°
        :param gamma: å­£èŠ‚å¹³æ»‘ç³»æ•°
        :param seasonal_period: å­£èŠ‚å‘¨æœŸ
        :param n_forecast: é¢„æµ‹æ­¥æ•°
        """
        n = self.n
        m = seasonal_period
        
        # åˆå§‹åŒ–
        level = np.zeros(n + n_forecast)
        trend = np.zeros(n + n_forecast)
        seasonal = np.zeros(n + n_forecast)
        fitted = np.zeros(n + n_forecast)
        
        # åˆå§‹å€¼
        level[0] = np.mean(self.values[:m])
        trend[0] = (np.mean(self.values[m:2*m]) - np.mean(self.values[:m])) / m
        for i in range(m):
            seasonal[i] = self.values[i] - level[0]
        
        # æ‹Ÿåˆ
        for t in range(1, n):
            level[t] = alpha * (self.values[t] - seasonal[t-m]) + (1 - alpha) * (level[t-1] + trend[t-1])
            trend[t] = beta * (level[t] - level[t-1]) + (1 - beta) * trend[t-1]
            seasonal[t] = gamma * (self.values[t] - level[t]) + (1 - gamma) * seasonal[t-m]
            fitted[t] = level[t-1] + trend[t-1] + seasonal[t-m]
        
        # é¢„æµ‹
        for t in range(n, n + n_forecast):
            level[t] = level[n-1] + (t - n + 1) * trend[n-1]
            fitted[t] = level[t] + seasonal[t-m]
        
        return {
            'fitted': fitted[:n],
            'forecast': fitted[n:],
            'level': level,
            'trend': trend,
            'seasonal': seasonal
        }
    
    def decompose(self, period=7, model='additive'):
        """
        æ—¶é—´åºåˆ—åˆ†è§£
        
        :param period: å­£èŠ‚å‘¨æœŸ
        :param model: 'additive' æˆ– 'multiplicative'
        """
        # è¶‹åŠ¿ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
        trend = self.moving_average(window=period)
        
        if model == 'additive':
            detrended = self.values - trend
        else:
            detrended = self.values / (trend + 1e-10)
        
        # å­£èŠ‚æ€§ï¼ˆæŒ‰å‘¨æœŸå¹³å‡ï¼‰
        seasonal = np.zeros(self.n)
        for i in range(period):
            indices = np.arange(i, self.n, period)
            valid_indices = indices[~np.isnan(detrended[indices])]
            if len(valid_indices) > 0:
                seasonal[indices] = np.nanmean(detrended[valid_indices])
        
        # æ®‹å·®
        if model == 'additive':
            residual = self.values - trend - seasonal
        else:
            residual = self.values / ((trend + 1e-10) * (seasonal + 1e-10))
        
        self.decomposition = {
            'observed': self.values,
            'trend': trend,
            'seasonal': seasonal,
            'residual': residual,
            'model': model
        }
        
        return self.decomposition
    
    def compute_metrics(self, actual, predicted):
        """è®¡ç®—é¢„æµ‹è¯„ä»·æŒ‡æ ‡"""
        mask = ~np.isnan(actual) & ~np.isnan(predicted)
        actual = actual[mask]
        predicted = predicted[mask]
        
        mse = mean_squared_error(actual, predicted)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(actual, predicted)
        mape = np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100
        r2 = r2_score(actual, predicted)
        
        return {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'MAPE': mape,
            'R2': r2
        }


# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šç§»åŠ¨å¹³å‡é¢„æµ‹ (Moving Average Prediction)
# ============================================================

class MovingAveragePredictor:
    """
    ç§»åŠ¨å¹³å‡é¢„æµ‹å™¨
    
    æ–¹æ³•ï¼š
    - ç®€å•ç§»åŠ¨å¹³å‡ (SMA)
    - åŠ æƒç§»åŠ¨å¹³å‡ (WMA)
    - æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA)
    """
    
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.history = None
        self.predictions = None
        self.metrics = None
    
    def fit_predict(self, data, window=7, method='simple', n_forecast=7):
        """
        æ‹Ÿåˆå¹¶é¢„æµ‹
        
        :param data: æ—¶é—´åºåˆ—æ•°æ®
        :param window: ç§»åŠ¨çª—å£å¤§å°
        :param method: 'simple', 'weighted', 'exponential'
        :param n_forecast: é¢„æµ‹æ­¥æ•°
        """
        if isinstance(data, pd.DataFrame):
            values = data.iloc[:, -1].values if 'value' not in data.columns else data['value'].values
        else:
            values = np.array(data)
        
        n = len(values)
        fitted = np.zeros(n)
        
        if method == 'simple':
            # ç®€å•ç§»åŠ¨å¹³å‡
            for t in range(window, n):
                fitted[t] = np.mean(values[t-window:t])
            fitted[:window] = np.nan
            
            # é¢„æµ‹
            forecast = np.zeros(n_forecast)
            last_values = list(values[-window:])
            for i in range(n_forecast):
                forecast[i] = np.mean(last_values)
                last_values.pop(0)
                last_values.append(forecast[i])
        
        elif method == 'weighted':
            # åŠ æƒç§»åŠ¨å¹³å‡
            weights = np.arange(1, window + 1)
            weights = weights / weights.sum()
            
            for t in range(window, n):
                fitted[t] = np.sum(weights * values[t-window:t])
            fitted[:window] = np.nan
            
            forecast = np.zeros(n_forecast)
            last_values = list(values[-window:])
            for i in range(n_forecast):
                forecast[i] = np.sum(weights * last_values)
                last_values.pop(0)
                last_values.append(forecast[i])
        
        elif method == 'exponential':
            # æŒ‡æ•°ç§»åŠ¨å¹³å‡
            alpha = 2 / (window + 1)
            fitted[0] = values[0]
            for t in range(1, n):
                fitted[t] = alpha * values[t] + (1 - alpha) * fitted[t-1]
            
            forecast = np.zeros(n_forecast)
            last_ema = fitted[-1]
            for i in range(n_forecast):
                forecast[i] = last_ema  # EMAè¶‹äºç¨³å®š
        
        self.history = values
        self.fitted = fitted
        self.predictions = forecast
        
        # è®¡ç®—è¯„ä»·æŒ‡æ ‡
        valid_idx = ~np.isnan(fitted)
        self.metrics = {
            'RMSE': np.sqrt(mean_squared_error(values[valid_idx], fitted[valid_idx])),
            'MAE': mean_absolute_error(values[valid_idx], fitted[valid_idx]),
            'MAPE': np.mean(np.abs((values[valid_idx] - fitted[valid_idx]) / 
                                   (values[valid_idx] + 1e-10))) * 100
        }
        
        if self.verbose:
            self._print_results(method, window)
        
        return self
    
    def _print_results(self, method, window):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*60)
        print(f"ğŸ“Š ç§»åŠ¨å¹³å‡é¢„æµ‹ç»“æœ ({method.upper()}, window={window})")
        print("="*60)
        print(f"  RMSE: {self.metrics['RMSE']:.4f}")
        print(f"  MAE:  {self.metrics['MAE']:.4f}")
        print(f"  MAPE: {self.metrics['MAPE']:.2f}%")
        print(f"  é¢„æµ‹å€¼: {self.predictions[:5].round(2)} ...")
        print("="*60)
    
    def get_forecast(self):
        """è·å–é¢„æµ‹ç»“æœ"""
        return self.predictions


# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šå›å½’é¢„æµ‹å™¨ (Regression Predictor)
# ============================================================

class RegressionPredictor:
    """
    å›å½’é¢„æµ‹å™¨
    
    æ¨¡å‹ï¼š
    - çº¿æ€§å›å½’
    - Ridgeå›å½’ï¼ˆL2æ­£åˆ™åŒ–ï¼‰
    - Lassoå›å½’ï¼ˆL1æ­£åˆ™åŒ–ï¼‰
    - éšæœºæ£®æ—å›å½’
    - æ¢¯åº¦æå‡å›å½’
    """
    
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.metrics = None
        self.feature_importance = None
    
    def fit(self, X, y, model_type='random_forest', 
            test_size=0.2, scale=True, **kwargs):
        """
        æ‹Ÿåˆæ¨¡å‹
        
        :param X: ç‰¹å¾çŸ©é˜µ
        :param y: ç›®æ ‡å˜é‡
        :param model_type: æ¨¡å‹ç±»å‹
        :param test_size: æµ‹è¯•é›†æ¯”ä¾‹
        :param scale: æ˜¯å¦æ ‡å‡†åŒ–
        :param kwargs: æ¨¡å‹é¢å¤–å‚æ•°
        """
        if isinstance(X, pd.DataFrame):
            self.feature_names = list(X.columns)
            X = X.values
        else:
            self.feature_names = [f"ç‰¹å¾{i+1}" for i in range(X.shape[1])]
        
        if isinstance(y, pd.Series):
            y = y.values
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # æ ‡å‡†åŒ–
        if scale:
            self.scaler = StandardScaler()
            X_train = self.scaler.fit_transform(X_train)
            X_test = self.scaler.transform(X_test)
        
        # é€‰æ‹©æ¨¡å‹
        if model_type == 'linear':
            self.model = LinearRegression(**kwargs)
        elif model_type == 'ridge':
            self.model = Ridge(alpha=kwargs.get('alpha', 1.0))
        elif model_type == 'lasso':
            self.model = Lasso(alpha=kwargs.get('alpha', 1.0))
        elif model_type == 'random_forest':
            self.model = RandomForestRegressor(
                n_estimators=kwargs.get('n_estimators', 100),
                max_depth=kwargs.get('max_depth', None),
                random_state=42
            )
        elif model_type == 'gradient_boosting':
            self.model = GradientBoostingRegressor(
                n_estimators=kwargs.get('n_estimators', 100),
                learning_rate=kwargs.get('learning_rate', 0.1),
                max_depth=kwargs.get('max_depth', 3),
                random_state=42
            )
        
        # è®­ç»ƒ
        self.model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(X_train)
        y_test_pred = self.model.predict(X_test)
        
        # è¯„ä¼°
        self.metrics = {
            'train': {
                'R2': r2_score(y_train, y_train_pred),
                'RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),
                'MAE': mean_absolute_error(y_train, y_train_pred)
            },
            'test': {
                'R2': r2_score(y_test, y_test_pred),
                'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),
                'MAE': mean_absolute_error(y_test, y_test_pred)
            }
        }
        
        # ç‰¹å¾é‡è¦æ€§
        if hasattr(self.model, 'feature_importances_'):
            self.feature_importance = pd.Series(
                self.model.feature_importances_, 
                index=self.feature_names
            )
        elif hasattr(self.model, 'coef_'):
            self.feature_importance = pd.Series(
                np.abs(self.model.coef_), 
                index=self.feature_names
            )
        
        if self.verbose:
            self._print_results(model_type)
        
        return self
    
    def _print_results(self, model_type):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*60)
        print(f"ğŸ“Š å›å½’æ¨¡å‹ç»“æœ ({model_type})")
        print("="*60)
        print("\n  è®­ç»ƒé›†:")
        print(f"    RÂ²:   {self.metrics['train']['R2']:.4f}")
        print(f"    RMSE: {self.metrics['train']['RMSE']:.4f}")
        print(f"    MAE:  {self.metrics['train']['MAE']:.4f}")
        print("\n  æµ‹è¯•é›†:")
        print(f"    RÂ²:   {self.metrics['test']['R2']:.4f}")
        print(f"    RMSE: {self.metrics['test']['RMSE']:.4f}")
        print(f"    MAE:  {self.metrics['test']['MAE']:.4f}")
        
        if self.feature_importance is not None:
            print("\n  ç‰¹å¾é‡è¦æ€§:")
            for name, imp in self.feature_importance.sort_values(ascending=False).items():
                print(f"    {name}: {imp:.4f}")
        print("="*60)
    
    def predict(self, X):
        """é¢„æµ‹"""
        if isinstance(X, pd.DataFrame):
            X = X.values
        if self.scaler is not None:
            X = self.scaler.transform(X)
        return self.model.predict(X)
    
    def cross_validate(self, X, y, cv=5):
        """äº¤å‰éªŒè¯"""
        if isinstance(X, pd.DataFrame):
            X = X.values
        if isinstance(y, pd.Series):
            y = y.values
        
        if self.scaler is not None:
            X = self.scaler.fit_transform(X)
        
        scores = cross_val_score(self.model, X, y, cv=cv, scoring='r2')
        
        print(f"\näº¤å‰éªŒè¯ RÂ² (cv={cv}):")
        print(f"  Mean: {scores.mean():.4f} Â± {scores.std():.4f}")
        print(f"  Scores: {scores.round(4)}")
        
        return scores


# ============================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šé›†æˆé¢„æµ‹å™¨ (Ensemble Predictor)
# ============================================================

class EnsemblePredictor:
    """
    é›†æˆé¢„æµ‹å™¨ - ç»“åˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹
    """
    
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.models = {}
        self.weights = None
        self.metrics = {}
    
    def add_model(self, name, model):
        """æ·»åŠ æ¨¡å‹"""
        self.models[name] = model
    
    def fit_all(self, X, y, test_size=0.2):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        if isinstance(X, pd.DataFrame):
            X = X.values
        if isinstance(y, pd.Series):
            y = y.values
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        predictions = {}
        
        for name, model in self.models.items():
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            predictions[name] = pred
            
            self.metrics[name] = {
                'R2': r2_score(y_test, pred),
                'RMSE': np.sqrt(mean_squared_error(y_test, pred))
            }
        
        # è®¡ç®—æœ€ä¼˜æƒé‡ï¼ˆåŸºäºR2åˆ†æ•°ï¼‰
        r2_scores = np.array([self.metrics[name]['R2'] for name in self.models])
        r2_scores = np.maximum(r2_scores, 0)  # ç¡®ä¿éè´Ÿ
        self.weights = r2_scores / (r2_scores.sum() + 1e-10)
        
        # é›†æˆé¢„æµ‹
        ensemble_pred = np.zeros_like(y_test, dtype=float)
        for i, name in enumerate(self.models):
            ensemble_pred += self.weights[i] * predictions[name]
        
        self.metrics['Ensemble'] = {
            'R2': r2_score(y_test, ensemble_pred),
            'RMSE': np.sqrt(mean_squared_error(y_test, ensemble_pred))
        }
        
        if self.verbose:
            self._print_comparison()
        
        return self
    
    def _print_comparison(self):
        """æ‰“å°æ¨¡å‹å¯¹æ¯”"""
        print("\n" + "="*60)
        print("ğŸ“Š é›†æˆæ¨¡å‹å¯¹æ¯”")
        print("="*60)
        print(f"\n  {'æ¨¡å‹':<20} {'RÂ²':>10} {'RMSE':>10}")
        print("  " + "-"*40)
        for name, metrics in self.metrics.items():
            print(f"  {name:<20} {metrics['R2']:>10.4f} {metrics['RMSE']:>10.4f}")
        print("\n  æ¨¡å‹æƒé‡:", dict(zip(self.models.keys(), self.weights.round(4))))
        print("="*60)
    
    def predict(self, X):
        """é›†æˆé¢„æµ‹"""
        if isinstance(X, pd.DataFrame):
            X = X.values
        
        pred = np.zeros(X.shape[0])
        for i, (name, model) in enumerate(self.models.items()):
            pred += self.weights[i] * model.predict(X)
        
        return pred


# ============================================================
# ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå¯è§†åŒ–æ¨¡å— (Visualization)
# ============================================================

class PredictionVisualizer:
    """é¢„æµ‹æ¨¡å‹å¯è§†åŒ–ç±»"""
    
    def __init__(self):
        self.colors = PlotStyleConfig.COLORS
    
    def plot_time_series(self, dates, actual, predicted=None, 
                         forecast_dates=None, forecast=None,
                         title="æ—¶é—´åºåˆ—é¢„æµ‹", save_path=None):
        """ç»˜åˆ¶æ—¶é—´åºåˆ—é¢„æµ‹å›¾"""
        fig, ax = plt.subplots(figsize=(14, 6))
        
        ax.plot(dates, actual, 'o-', markersize=3, linewidth=1.5,
               color=self.colors['actual'], label='å®é™…å€¼', alpha=0.8)
        
        if predicted is not None:
            ax.plot(dates, predicted, '-', linewidth=2,
                   color=self.colors['predicted'], label='æ‹Ÿåˆå€¼')
        
        if forecast is not None and forecast_dates is not None:
            ax.plot(forecast_dates, forecast, '--', linewidth=2,
                   color=self.colors['confidence'], label='é¢„æµ‹å€¼')
            ax.axvline(x=dates.iloc[-1] if hasattr(dates, 'iloc') else dates[-1],
                      color='gray', linestyle=':', alpha=0.7)
        
        ax.set_xlabel('æ—¥æœŸ', fontweight='bold')
        ax.set_ylabel('å€¼', fontweight='bold')
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_decomposition(self, decomposition, title="æ—¶é—´åºåˆ—åˆ†è§£", save_path=None):
        """ç»˜åˆ¶æ—¶é—´åºåˆ—åˆ†è§£å›¾"""
        fig, axes = plt.subplots(4, 1, figsize=(14, 12), sharex=True)
        
        components = ['observed', 'trend', 'seasonal', 'residual']
        titles = ['(a) åŸå§‹åºåˆ—', '(b) è¶‹åŠ¿æˆåˆ†', '(c) å­£èŠ‚æˆåˆ†', '(d) æ®‹å·®']
        colors = [self.colors['primary'], self.colors['secondary'], 
                  self.colors['accent'], self.colors['neutral']]
        
        for ax, comp, t, c in zip(axes, components, titles, colors):
            ax.plot(decomposition[comp], color=c, linewidth=1.5)
            ax.set_ylabel(t, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        axes[-1].set_xlabel('æ—¶é—´', fontweight='bold')
        plt.suptitle(title, fontsize=14, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_actual_vs_predicted(self, actual, predicted, 
                                  title="å®é™…å€¼ vs é¢„æµ‹å€¼", save_path=None):
        """ç»˜åˆ¶å®é™…å€¼ä¸é¢„æµ‹å€¼æ•£ç‚¹å›¾"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # æ•£ç‚¹å›¾
        ax1 = axes[0]
        ax1.scatter(actual, predicted, alpha=0.6, 
                   color=self.colors['primary'], edgecolors='white')
        
        # å¯¹è§’çº¿
        min_val = min(actual.min(), predicted.min())
        max_val = max(actual.max(), predicted.max())
        ax1.plot([min_val, max_val], [min_val, max_val], 
                'r--', linewidth=2, label='y=x (å®Œç¾é¢„æµ‹)')
        
        ax1.set_xlabel('å®é™…å€¼', fontweight='bold')
        ax1.set_ylabel('é¢„æµ‹å€¼', fontweight='bold')
        ax1.set_title('(a) é¢„æµ‹æ•£ç‚¹å›¾', fontsize=12, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ®‹å·®å›¾
        ax2 = axes[1]
        residuals = actual - predicted
        ax2.scatter(predicted, residuals, alpha=0.6,
                   color=self.colors['secondary'], edgecolors='white')
        ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)
        ax2.set_xlabel('é¢„æµ‹å€¼', fontweight='bold')
        ax2.set_ylabel('æ®‹å·®', fontweight='bold')
        ax2.set_title('(b) æ®‹å·®å›¾', fontsize=12, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        plt.suptitle(title, fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_feature_importance(self, importance, title="ç‰¹å¾é‡è¦æ€§", save_path=None):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        importance = importance.sort_values(ascending=True)
        colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(importance)))
        
        bars = ax.barh(importance.index, importance.values, 
                      color=colors, edgecolor='white', linewidth=2)
        
        ax.set_xlabel('é‡è¦æ€§', fontweight='bold')
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='x')
        
        for bar, val in zip(bars, importance.values):
            ax.text(val + max(importance.values)*0.02, bar.get_y() + bar.get_height()/2,
                   f'{val:.4f}', va='center', fontsize=10)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_model_comparison(self, metrics_dict, title="æ¨¡å‹æ€§èƒ½å¯¹æ¯”", save_path=None):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        models = list(metrics_dict.keys())
        r2_values = [metrics_dict[m]['R2'] for m in models]
        rmse_values = [metrics_dict[m]['RMSE'] for m in models]
        
        colors = PlotStyleConfig.PALETTE[:len(models)]
        
        # RÂ²å¯¹æ¯”
        ax1 = axes[0]
        bars1 = ax1.bar(models, r2_values, color=colors, edgecolor='white', linewidth=2)
        ax1.set_ylabel('RÂ²', fontweight='bold')
        ax1.set_title('(a) RÂ² Score', fontsize=12, fontweight='bold')
        ax1.set_ylim(0, 1)
        for bar, val in zip(bars1, r2_values):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                    f'{val:.4f}', ha='center', va='bottom', fontsize=10)
        
        # RMSEå¯¹æ¯”
        ax2 = axes[1]
        bars2 = ax2.bar(models, rmse_values, color=colors, edgecolor='white', linewidth=2)
        ax2.set_ylabel('RMSE', fontweight='bold')
        ax2.set_title('(b) RMSE', fontsize=12, fontweight='bold')
        for bar, val in zip(bars2, rmse_values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(rmse_values)*0.02,
                    f'{val:.4f}', ha='center', va='bottom', fontsize=10)
        
        plt.suptitle(title, fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()


# ============================================================
# ç¬¬å…«éƒ¨åˆ†ï¼šä¸»ç¨‹åºä¸å®Œæ•´ç¤ºä¾‹ (Main Program)
# ============================================================

if __name__ == "__main__":
    
    print("\n" + "="*70)
    print("   PREDICTION MODELS FOR MCM/ICM")
    print("   é¢„æµ‹ç±»æ¨¡å‹ - æ—¶é—´åºåˆ— + å›å½’åˆ†æ")
    print("   Extended Version with Visualization")
    print("="*70)
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                    ğŸ“Š é¢„æµ‹æ¨¡å‹åˆ†ææµç¨‹                            â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                                  â•‘
    â•‘   [æ—¶é—´åºåˆ—é¢„æµ‹]                                                  â•‘
    â•‘      â”œâ”€ ç§»åŠ¨å¹³å‡ (MA): ç®€å•ã€åŠ æƒã€æŒ‡æ•°                           â•‘
    â•‘      â”œâ”€ æŒ‡æ•°å¹³æ»‘: å•æŒ‡æ•°ã€åŒæŒ‡æ•°ã€ä¸‰æŒ‡æ•°                          â•‘
    â•‘      â””â”€ åˆ†è§£: è¶‹åŠ¿ + å­£èŠ‚æ€§ + æ®‹å·®                               â•‘
    â•‘                                                                  â•‘
    â•‘   [å›å½’é¢„æµ‹]                                                      â•‘
    â•‘      â”œâ”€ çº¿æ€§å›å½’: Linear, Ridge, Lasso                           â•‘
    â•‘      â”œâ”€ é›†æˆæ–¹æ³•: RandomForest, GradientBoosting                 â•‘
    â•‘      â””â”€ æ¨¡å‹è¯„ä¼°: RÂ², RMSE, MAE, MAPE                            â•‘
    â•‘                                                                  â•‘
    â•‘   [æ¨¡å‹é€‰æ‹©å»ºè®®]                                                  â•‘
    â•‘      â”œâ”€ è¶‹åŠ¿æ˜æ˜¾ â†’ çº¿æ€§å›å½’ã€æŒ‡æ•°å¹³æ»‘                             â•‘
    â•‘      â”œâ”€ å­£èŠ‚æ€§å¼º â†’ Holt-Wintersã€åˆ†è§£æ³•                          â•‘
    â•‘      â””â”€ å¤æ‚å…³ç³» â†’ RandomForestã€GradientBoosting                â•‘
    â•‘                                                                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    visualizer = PredictionVisualizer()
    generator = TimeSeriesGenerator(random_seed=2026)
    
    # ================================================================
    # ç¤ºä¾‹1ï¼šæ—¶é—´åºåˆ—åˆ†è§£ä¸é¢„æµ‹
    # ================================================================
    print("\n" + "="*70)
    print("ğŸ“ EXAMPLE 1: æ—¶é—´åºåˆ—åˆ†è§£ä¸ç§»åŠ¨å¹³å‡é¢„æµ‹")
    print("="*70)
    
    # ç”Ÿæˆæ•°æ®
    ts_data = generator.generate_trend_seasonal(
        n_periods=180, 
        trend_type='linear',
        seasonal_period=7,
        noise_level=15
    )
    
    print(f"\næ•°æ®æ¦‚è§ˆ:")
    print(f"  æ—¶é—´èŒƒå›´: {ts_data['date'].min()} åˆ° {ts_data['date'].max()}")
    print(f"  æ•°æ®ç‚¹æ•°: {len(ts_data)}")
    
    # æ—¶é—´åºåˆ—åˆ†æ
    analyzer = TimeSeriesAnalyzer(ts_data, 'date', 'value')
    decomposition = analyzer.decompose(period=7)
    
    # å¯è§†åŒ–åˆ†è§£
    visualizer.plot_decomposition(decomposition, title="æ—¶é—´åºåˆ—åˆ†è§£ (å‘¨æœŸ=7)")
    
    # ç§»åŠ¨å¹³å‡é¢„æµ‹
    print("\nç§»åŠ¨å¹³å‡é¢„æµ‹:")
    
    ma_predictor = MovingAveragePredictor(verbose=True)
    
    # ç®€å•ç§»åŠ¨å¹³å‡
    ma_predictor.fit_predict(ts_data['value'], window=7, method='simple', n_forecast=14)
    
    # æŒ‡æ•°ç§»åŠ¨å¹³å‡
    ma_predictor.fit_predict(ts_data['value'], window=7, method='exponential', n_forecast=14)
    
    # å¯è§†åŒ–
    forecast_dates = pd.date_range(
        start=ts_data['date'].iloc[-1] + timedelta(days=1),
        periods=14
    )
    
    visualizer.plot_time_series(
        dates=ts_data['date'],
        actual=ts_data['value'].values,
        predicted=ma_predictor.fitted,
        forecast_dates=forecast_dates,
        forecast=ma_predictor.predictions,
        title="ç§»åŠ¨å¹³å‡é¢„æµ‹ç»“æœ"
    )
    
    # ================================================================
    # ç¤ºä¾‹2ï¼šHolt-Wintersä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘
    # ================================================================
    print("\n" + "="*70)
    print("ğŸ“ EXAMPLE 2: Holt-Wintersä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘")
    print("="*70)
    
    hw_result = analyzer.holt_winters(
        alpha=0.3, beta=0.1, gamma=0.1,
        seasonal_period=7, n_forecast=30
    )
    
    print(f"\né¢„æµ‹æœªæ¥30å¤©:")
    print(f"  é¢„æµ‹å‡å€¼: {np.mean(hw_result['forecast']):.2f}")
    print(f"  é¢„æµ‹èŒƒå›´: [{np.min(hw_result['forecast']):.2f}, {np.max(hw_result['forecast']):.2f}]")
    
    # è®¡ç®—è¯„ä»·æŒ‡æ ‡
    metrics = analyzer.compute_metrics(ts_data['value'].values, hw_result['fitted'])
    print(f"\n  æ¨¡å‹è¯„ä»·:")
    print(f"    RMSE: {metrics['RMSE']:.4f}")
    print(f"    MAPE: {metrics['MAPE']:.2f}%")
    print(f"    RÂ²:   {metrics['R2']:.4f}")
    
    # å¯è§†åŒ–
    forecast_dates_hw = pd.date_range(
        start=ts_data['date'].iloc[-1] + timedelta(days=1),
        periods=30
    )
    
    visualizer.plot_time_series(
        dates=ts_data['date'],
        actual=ts_data['value'].values,
        predicted=hw_result['fitted'],
        forecast_dates=forecast_dates_hw,
        forecast=hw_result['forecast'],
        title="Holt-Wintersä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘é¢„æµ‹"
    )
    
    # ================================================================
    # ç¤ºä¾‹3ï¼šå¤šå˜é‡å›å½’é¢„æµ‹
    # ================================================================
    print("\n" + "="*70)
    print("ğŸ“ EXAMPLE 3: å¤šå˜é‡å›å½’é¢„æµ‹ï¼ˆé”€é‡é¢„æµ‹ï¼‰")
    print("="*70)
    
    # ç”Ÿæˆå¤šå˜é‡æ•°æ®
    reg_data = generator.generate_multivariate(n_samples=300)
    print(f"\næ•°æ®æ¦‚è§ˆ:")
    print(reg_data.describe().round(2))
    
    X = reg_data[['å¹¿å‘ŠæŠ•å…¥', 'å®¢æµé‡', 'ä¿ƒé”€åŠ›åº¦']]
    y = reg_data['é”€é‡']
    
    # è®­ç»ƒå¤šä¸ªæ¨¡å‹
    print("\n--- çº¿æ€§å›å½’ ---")
    linear_predictor = RegressionPredictor(verbose=True)
    linear_predictor.fit(X, y, model_type='linear')
    
    print("\n--- éšæœºæ£®æ—å›å½’ ---")
    rf_predictor = RegressionPredictor(verbose=True)
    rf_predictor.fit(X, y, model_type='random_forest', n_estimators=100)
    
    print("\n--- æ¢¯åº¦æå‡å›å½’ ---")
    gb_predictor = RegressionPredictor(verbose=True)
    gb_predictor.fit(X, y, model_type='gradient_boosting', n_estimators=100)
    
    # ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
    if rf_predictor.feature_importance is not None:
        visualizer.plot_feature_importance(
            rf_predictor.feature_importance,
            title="éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§"
        )
    
    # æ¨¡å‹å¯¹æ¯”
    all_metrics = {
        'Linear': linear_predictor.metrics['test'],
        'RandomForest': rf_predictor.metrics['test'],
        'GradientBoosting': gb_predictor.metrics['test']
    }
    visualizer.plot_model_comparison(all_metrics, title="å›å½’æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    # ================================================================
    # ç¤ºä¾‹4ï¼šé›†æˆå­¦ä¹ 
    # ================================================================
    print("\n" + "="*70)
    print("ğŸ“ EXAMPLE 4: é›†æˆå­¦ä¹ é¢„æµ‹")
    print("="*70)
    
    ensemble = EnsemblePredictor(verbose=True)
    ensemble.add_model('Linear', LinearRegression())
    ensemble.add_model('Ridge', Ridge(alpha=1.0))
    ensemble.add_model('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42))
    ensemble.add_model('GradientBoosting', GradientBoostingRegressor(n_estimators=100, random_state=42))
    
    ensemble.fit_all(X.values, y.values, test_size=0.2)
    
    visualizer.plot_model_comparison(ensemble.metrics, title="é›†æˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    # ================================================================
    # ç¤ºä¾‹5ï¼šäº¤å‰éªŒè¯
    # ================================================================
    print("\n" + "="*70)
    print("ğŸ“ EXAMPLE 5: äº¤å‰éªŒè¯")
    print("="*70)
    
    print("\néšæœºæ£®æ—äº¤å‰éªŒè¯:")
    rf_predictor.cross_validate(X, y, cv=5)
    
    # ================================================================
    # ä½¿ç”¨è¯´æ˜
    # ================================================================
    print("\n" + "="*70)
    print("ğŸ“– ä½¿ç”¨è¯´æ˜ (Usage Guide)")
    print("="*70)
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     é¢„æµ‹æ¨¡å‹ä½¿ç”¨æŒ‡å—                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ã€æ—¶é—´åºåˆ—é¢„æµ‹ã€‘
    
    1ï¸âƒ£ ç§»åŠ¨å¹³å‡
       predictor = MovingAveragePredictor()
       predictor.fit_predict(data, window=7, method='simple')
    
    2ï¸âƒ£ Holt-Winters
       analyzer = TimeSeriesAnalyzer(data)
       result = analyzer.holt_winters(alpha=0.3, beta=0.1, gamma=0.1)
    
    ã€å›å½’é¢„æµ‹ã€‘
    
    1ï¸âƒ£ å•æ¨¡å‹
       predictor = RegressionPredictor()
       predictor.fit(X, y, model_type='random_forest')
       predictions = predictor.predict(X_new)
    
    2ï¸âƒ£ é›†æˆæ¨¡å‹
       ensemble = EnsemblePredictor()
       ensemble.add_model('RF', RandomForestRegressor())
       ensemble.fit_all(X, y)
    
    ã€æ¨¡å‹é€‰æ‹©å»ºè®®ã€‘
    
    - æ•°æ®é‡å°(<100): çº¿æ€§å›å½’ã€Ridge
    - æ•°æ®é‡ä¸­ç­‰: éšæœºæ£®æ—
    - æ•°æ®é‡å¤§(>1000): æ¢¯åº¦æå‡ã€ç¥ç»ç½‘ç»œ
    - æœ‰å­£èŠ‚æ€§: Holt-Winters
    
    ã€è®ºæ–‡å›¾è¡¨å»ºè®®ã€‘
    
    Figure 1: æ—¶é—´åºåˆ—åˆ†è§£å›¾
    Figure 2: é¢„æµ‹ç»“æœä¸å®é™…å€¼å¯¹æ¯”
    Figure 3: æ®‹å·®åˆ†æå›¾
    Figure 4: ç‰¹å¾é‡è¦æ€§
    Figure 5: æ¨¡å‹æ€§èƒ½å¯¹æ¯”ï¼ˆRÂ², RMSEæŸ±çŠ¶å›¾ï¼‰
    
    Table 1: æ¨¡å‹å‚æ•°è®¾ç½®
    Table 2: é¢„æµ‹è¯„ä»·æŒ‡æ ‡ï¼ˆRMSE, MAE, MAPE, RÂ²ï¼‰
    Table 3: äº¤å‰éªŒè¯ç»“æœ
    """)
    
    print("\n" + "="*70)
    print("   âœ… All examples completed successfully!")
    print("   ğŸ’¡ Use the above code templates for your MCM/ICM paper")
    print("="*70)
