"""
============================================================
è´å¶æ–¯æ¨æ–­æ¨¡å‹ (Bayesian Inference Model)
é€‚ç”¨äºç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› (MCM/ICM)
============================================================
åŠŸèƒ½ï¼šç”±æœæ¨å› ã€å‚æ•°ä¼°è®¡ã€ä¸ç¡®å®šæ€§é‡åŒ–ã€åéªŒåˆ†å¸ƒè®¡ç®—
åŸç†ï¼šè´å¶æ–¯å®šç† P(Î¸|D) âˆ P(D|Î¸) Ã— P(Î¸)
ä½œè€…ï¼šMCM/ICM Team
æ—¥æœŸï¼š2026å¹´1æœˆ
============================================================

åº”ç”¨åœºæ™¯ï¼š
- é€†é—®é¢˜ï¼šç”±è§‚æµ‹ç»“æœæ¨æ–­åŸå› /å‚æ•°
- å‚æ•°ä¸ç¡®å®šæ€§é‡åŒ–
- é¢„æµ‹åŒºé—´ä¼°è®¡
- æ¨¡å‹æ›´æ–°ï¼ˆæ–°æ•°æ®åˆ°æ¥æ—¶ï¼‰
- ç–¾ç—…è¯Šæ–­ã€è®¾å¤‡æ•…éšœè¯Šæ–­

æ ¸å¿ƒå…¬å¼ï¼š
åéªŒ âˆ ä¼¼ç„¶ Ã— å…ˆéªŒ
P(Î¸|Data) âˆ P(Data|Î¸) Ã— P(Î¸)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
from scipy.optimize import minimize
import warnings

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from visualization.plot_config import PlotStyleConfig, FigureSaver

PlotStyleConfig.setup_style()
warnings.filterwarnings('ignore')


class BayesianInference:
    """
    è´å¶æ–¯æ¨æ–­åŸºç¡€ç±»
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å…±è½­å…ˆéªŒåˆ†æï¼ˆæ­£æ€-æ­£æ€ã€Beta-äºŒé¡¹ç­‰ï¼‰
    2. ç½‘æ ¼è¿‘ä¼¼æ³•
    3. MCMCé‡‡æ ·ï¼ˆMetropolis-Hastingsï¼‰
    4. åéªŒåˆ†å¸ƒå¯è§†åŒ–
    5. è´å¶æ–¯å› å­è®¡ç®—
    """
    
    def __init__(self, verbose=True):
        """
        åˆå§‹åŒ–è´å¶æ–¯æ¨æ–­å™¨
        
        :param verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        self.prior = None
        self.posterior = None
        self.data = None
        self.samples = None
        
    def _print_header(self, title):
        """æ‰“å°æ ‡é¢˜"""
        print("\n" + "="*60)
        print(f"ğŸ“Š {title}")
        print("="*60)


class NormalNormalBayes(BayesianInference):
    """
    æ­£æ€-æ­£æ€å…±è½­æ¨¡å‹
    
    åœºæ™¯ï¼šå·²çŸ¥æ–¹å·®ÏƒÂ²ï¼Œä¼°è®¡å‡å€¼Î¼
    
    å…ˆéªŒï¼šÎ¼ ~ N(Î¼â‚€, Ï„â‚€Â²)
    ä¼¼ç„¶ï¼šX|Î¼ ~ N(Î¼, ÏƒÂ²)
    åéªŒï¼šÎ¼|X ~ N(Î¼â‚™, Ï„â‚™Â²)
    
    é€‚ç”¨ï¼šè¿ç»­æ•°æ®çš„å‡å€¼ä¼°è®¡ï¼Œå¦‚æµ‹é‡å€¼ã€è¯„åˆ†ç­‰
    """
    
    def __init__(self, prior_mu=0, prior_tau=10, known_sigma=1, verbose=True):
        """
        åˆå§‹åŒ–æ­£æ€-æ­£æ€æ¨¡å‹
        
        :param prior_mu: å…ˆéªŒå‡å€¼ Î¼â‚€
        :param prior_tau: å…ˆéªŒæ ‡å‡†å·® Ï„â‚€ï¼ˆåæ˜ ä¸ç¡®å®šæ€§ï¼‰
        :param known_sigma: å·²çŸ¥çš„æ•°æ®æ ‡å‡†å·® Ïƒ
        """
        super().__init__(verbose)
        self.prior_mu = prior_mu
        self.prior_tau = prior_tau
        self.known_sigma = known_sigma
        
        # åéªŒå‚æ•°
        self.posterior_mu = None
        self.posterior_tau = None
        
    def fit(self, data):
        """
        æ ¹æ®æ•°æ®æ›´æ–°åéªŒåˆ†å¸ƒ
        
        :param data: è§‚æµ‹æ•°æ®
        :return: self
        """
        self.data = np.array(data).flatten()
        n = len(self.data)
        x_bar = np.mean(self.data)
        
        # å…±è½­æ›´æ–°å…¬å¼
        prior_precision = 1 / self.prior_tau**2
        likelihood_precision = n / self.known_sigma**2
        
        posterior_precision = prior_precision + likelihood_precision
        self.posterior_tau = 1 / np.sqrt(posterior_precision)
        
        self.posterior_mu = (prior_precision * self.prior_mu + 
                            likelihood_precision * x_bar) / posterior_precision
        
        if self.verbose:
            self._print_results()
            
        return self
    
    def _print_results(self):
        """æ‰“å°æ¨æ–­ç»“æœ"""
        self._print_header("æ­£æ€-æ­£æ€ è´å¶æ–¯æ¨æ–­")
        print(f"\n  ğŸ“Œ å…ˆéªŒåˆ†å¸ƒ: N({self.prior_mu:.4f}, {self.prior_tau:.4f}Â²)")
        print(f"  ğŸ“Œ å·²çŸ¥æ ‡å‡†å·®: Ïƒ = {self.known_sigma:.4f}")
        print(f"\n  ğŸ“Š è§‚æµ‹æ•°æ®:")
        print(f"     æ ·æœ¬é‡ n = {len(self.data)}")
        print(f"     æ ·æœ¬å‡å€¼ xÌ„ = {np.mean(self.data):.4f}")
        print(f"\n  âœ¨ åéªŒåˆ†å¸ƒ: N({self.posterior_mu:.4f}, {self.posterior_tau:.4f}Â²)")
        print(f"\n  ğŸ“ˆ åéªŒç»Ÿè®¡:")
        print(f"     åéªŒå‡å€¼ (ç‚¹ä¼°è®¡): {self.posterior_mu:.4f}")
        print(f"     åéªŒæ ‡å‡†å·®: {self.posterior_tau:.4f}")
        
        ci_lower, ci_upper = self.credible_interval(0.95)
        print(f"     95% å¯ä¿¡åŒºé—´: [{ci_lower:.4f}, {ci_upper:.4f}]")
        print("="*60)
    
    def credible_interval(self, level=0.95):
        """
        è®¡ç®—åéªŒå¯ä¿¡åŒºé—´
        
        :param level: å¯ä¿¡æ°´å¹³ï¼ˆå¦‚0.95è¡¨ç¤º95%ï¼‰
        :return: (ä¸‹ç•Œ, ä¸Šç•Œ)
        """
        alpha = 1 - level
        lower = stats.norm.ppf(alpha/2, self.posterior_mu, self.posterior_tau)
        upper = stats.norm.ppf(1-alpha/2, self.posterior_mu, self.posterior_tau)
        return lower, upper
    
    def posterior_pdf(self, theta):
        """åéªŒæ¦‚ç‡å¯†åº¦"""
        return stats.norm.pdf(theta, self.posterior_mu, self.posterior_tau)
    
    def prior_pdf(self, theta):
        """å…ˆéªŒæ¦‚ç‡å¯†åº¦"""
        return stats.norm.pdf(theta, self.prior_mu, self.prior_tau)
    
    def predict(self, n_samples=1000):
        """
        åéªŒé¢„æµ‹åˆ†å¸ƒï¼ˆé¢„æµ‹æ–°è§‚æµ‹å€¼ï¼‰
        
        :param n_samples: ç”Ÿæˆæ ·æœ¬æ•°
        :return: é¢„æµ‹æ ·æœ¬
        """
        # ä»åéªŒåˆ†å¸ƒé‡‡æ ·Î¼ï¼Œç„¶åä»N(Î¼, ÏƒÂ²)é‡‡æ ·
        mu_samples = np.random.normal(self.posterior_mu, self.posterior_tau, n_samples)
        predictions = np.random.normal(mu_samples, self.known_sigma)
        return predictions
    
    def update(self, new_data):
        """
        åºåˆ—è´å¶æ–¯æ›´æ–°ï¼ˆæ–°æ•°æ®åˆ°æ¥æ—¶ï¼‰
        
        :param new_data: æ–°è§‚æµ‹æ•°æ®
        :return: self
        """
        # å°†å½“å‰åéªŒä½œä¸ºæ–°çš„å…ˆéªŒ
        self.prior_mu = self.posterior_mu
        self.prior_tau = self.posterior_tau
        
        # ç”¨æ–°æ•°æ®æ›´æ–°
        return self.fit(new_data)
    
    def plot_distributions(self, save_path=None):
        """ç»˜åˆ¶å…ˆéªŒã€ä¼¼ç„¶ã€åéªŒåˆ†å¸ƒ"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # ç¡®å®šç»˜å›¾èŒƒå›´
        x_min = min(self.prior_mu - 4*self.prior_tau, 
                   np.mean(self.data) - 4*self.known_sigma/np.sqrt(len(self.data)))
        x_max = max(self.prior_mu + 4*self.prior_tau,
                   np.mean(self.data) + 4*self.known_sigma/np.sqrt(len(self.data)))
        theta = np.linspace(x_min, x_max, 500)
        
        # 1. å…ˆéªŒåˆ†å¸ƒ
        prior = self.prior_pdf(theta)
        axes[0].plot(theta, prior, color=PlotStyleConfig.COLORS['primary'], linewidth=2.5)
        axes[0].fill_between(theta, prior, alpha=0.3, color=PlotStyleConfig.COLORS['primary'])
        axes[0].axvline(self.prior_mu, color='gray', linestyle='--', linewidth=1.5)
        axes[0].set_title('å…ˆéªŒåˆ†å¸ƒ P(Î¸)', fontsize=12, fontweight='bold')
        axes[0].set_xlabel('Î¸ (å‚æ•°)', fontweight='bold')
        axes[0].set_ylabel('æ¦‚ç‡å¯†åº¦', fontweight='bold')
        
        # 2. ä¼¼ç„¶å‡½æ•°
        n = len(self.data)
        x_bar = np.mean(self.data)
        se = self.known_sigma / np.sqrt(n)
        likelihood = stats.norm.pdf(theta, x_bar, se)
        axes[1].plot(theta, likelihood, color=PlotStyleConfig.COLORS['secondary'], linewidth=2.5)
        axes[1].fill_between(theta, likelihood, alpha=0.3, color=PlotStyleConfig.COLORS['secondary'])
        axes[1].axvline(x_bar, color='gray', linestyle='--', linewidth=1.5)
        axes[1].set_title('ä¼¼ç„¶å‡½æ•° P(D|Î¸)', fontsize=12, fontweight='bold')
        axes[1].set_xlabel('Î¸ (å‚æ•°)', fontweight='bold')
        
        # 3. åéªŒåˆ†å¸ƒ
        posterior = self.posterior_pdf(theta)
        axes[2].plot(theta, posterior, color=PlotStyleConfig.COLORS['danger'], linewidth=2.5)
        axes[2].fill_between(theta, posterior, alpha=0.3, color=PlotStyleConfig.COLORS['danger'])
        axes[2].axvline(self.posterior_mu, color='gray', linestyle='--', linewidth=1.5)
        
        # æ ‡è®°å¯ä¿¡åŒºé—´
        ci_lower, ci_upper = self.credible_interval(0.95)
        mask = (theta >= ci_lower) & (theta <= ci_upper)
        axes[2].fill_between(theta[mask], posterior[mask], alpha=0.5, 
                            color=PlotStyleConfig.COLORS['accent'], label='95% CI')
        
        axes[2].set_title('åéªŒåˆ†å¸ƒ P(Î¸|D)', fontsize=12, fontweight='bold')
        axes[2].set_xlabel('Î¸ (å‚æ•°)', fontweight='bold')
        axes[2].legend()
        
        for ax in axes:
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
        
        plt.suptitle('è´å¶æ–¯æ¨æ–­: å…ˆéªŒ Ã— ä¼¼ç„¶ â†’ åéªŒ', fontsize=14, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        if save_path:
            saver = FigureSaver(os.path.dirname(save_path))
            saver.save(fig, os.path.basename(save_path).split('.')[0])
        
        return fig, axes
    
    def plot_updating(self, data_sequence, save_path=None):
        """
        å¯è§†åŒ–åºåˆ—è´å¶æ–¯æ›´æ–°è¿‡ç¨‹
        
        :param data_sequence: æ•°æ®åºåˆ—åˆ—è¡¨ [[ç¬¬1æ‰¹], [ç¬¬2æ‰¹], ...]
        """
        fig, ax = plt.subplots(figsize=(12, 7))
        
        # é‡ç½®åˆ°åŸå§‹å…ˆéªŒ
        current_mu = self.prior_mu
        current_tau = self.prior_tau
        
        theta = np.linspace(current_mu - 5*current_tau, 
                           current_mu + 5*current_tau, 500)
        
        colors = PlotStyleConfig.get_palette(len(data_sequence) + 1)
        
        # ç»˜åˆ¶å…ˆéªŒ
        prior = stats.norm.pdf(theta, current_mu, current_tau)
        ax.plot(theta, prior, color=colors[0], linewidth=2, 
               linestyle='--', label='å…ˆéªŒ', alpha=0.7)
        
        # é€æ­¥æ›´æ–°å¹¶ç»˜åˆ¶
        for i, data_batch in enumerate(data_sequence):
            n = len(data_batch)
            x_bar = np.mean(data_batch)
            
            prior_precision = 1 / current_tau**2
            likelihood_precision = n / self.known_sigma**2
            posterior_precision = prior_precision + likelihood_precision
            
            new_tau = 1 / np.sqrt(posterior_precision)
            new_mu = (prior_precision * current_mu + 
                     likelihood_precision * x_bar) / posterior_precision
            
            posterior = stats.norm.pdf(theta, new_mu, new_tau)
            ax.plot(theta, posterior, color=colors[i+1], linewidth=2.5,
                   label=f'æ‰¹æ¬¡{i+1}å (n={n})')
            
            current_mu, current_tau = new_mu, new_tau
        
        ax.set_xlabel('Î¸ (å‚æ•°)', fontsize=12, fontweight='bold')
        ax.set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=12, fontweight='bold')
        ax.set_title('è´å¶æ–¯åºåˆ—æ›´æ–°è¿‡ç¨‹', fontsize=14, fontweight='bold', pad=15)
        ax.legend(loc='upper right')
        
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            saver = FigureSaver(os.path.dirname(save_path))
            saver.save(fig, os.path.basename(save_path).split('.')[0])
        
        return fig, ax


class BetaBinomialBayes(BayesianInference):
    """
    Beta-äºŒé¡¹å…±è½­æ¨¡å‹
    
    åœºæ™¯ï¼šä¼°è®¡æˆåŠŸæ¦‚ç‡ pï¼ˆå¦‚ç‚¹å‡»ç‡ã€è½¬åŒ–ç‡ã€åˆæ ¼ç‡ï¼‰
    
    å…ˆéªŒï¼šp ~ Beta(Î±, Î²)
    ä¼¼ç„¶ï¼šX|p ~ Binomial(n, p)
    åéªŒï¼šp|X ~ Beta(Î± + k, Î² + n - k)
    
    é€‚ç”¨ï¼šäºŒå€¼æ•°æ®çš„æ¦‚ç‡ä¼°è®¡
    """
    
    def __init__(self, prior_alpha=1, prior_beta=1, verbose=True):
        """
        åˆå§‹åŒ–Beta-äºŒé¡¹æ¨¡å‹
        
        :param prior_alpha: Betaå…ˆéªŒå‚æ•° Î±ï¼ˆå¯ç†è§£ä¸ºå…ˆéªŒæˆåŠŸæ¬¡æ•°ï¼‰
        :param prior_beta: Betaå…ˆéªŒå‚æ•° Î²ï¼ˆå¯ç†è§£ä¸ºå…ˆéªŒå¤±è´¥æ¬¡æ•°ï¼‰
        """
        super().__init__(verbose)
        self.prior_alpha = prior_alpha
        self.prior_beta = prior_beta
        
        # åéªŒå‚æ•°
        self.posterior_alpha = None
        self.posterior_beta = None
        self.n_trials = None
        self.n_success = None
        
    def fit(self, n_success, n_trials):
        """
        æ ¹æ®è§‚æµ‹æ›´æ–°åéªŒ
        
        :param n_success: æˆåŠŸæ¬¡æ•°
        :param n_trials: æ€»è¯•éªŒæ¬¡æ•°
        :return: self
        """
        self.n_success = n_success
        self.n_trials = n_trials
        
        # å…±è½­æ›´æ–°
        self.posterior_alpha = self.prior_alpha + n_success
        self.posterior_beta = self.prior_beta + (n_trials - n_success)
        
        if self.verbose:
            self._print_results()
            
        return self
    
    def _print_results(self):
        """æ‰“å°ç»“æœ"""
        self._print_header("Beta-äºŒé¡¹ è´å¶æ–¯æ¨æ–­")
        print(f"\n  ğŸ“Œ å…ˆéªŒåˆ†å¸ƒ: Beta({self.prior_alpha}, {self.prior_beta})")
        prior_mean = self.prior_alpha / (self.prior_alpha + self.prior_beta)
        print(f"     å…ˆéªŒå‡å€¼: {prior_mean:.4f}")
        
        print(f"\n  ğŸ“Š è§‚æµ‹æ•°æ®:")
        print(f"     æ€»è¯•éªŒ n = {self.n_trials}")
        print(f"     æˆåŠŸæ¬¡æ•° k = {self.n_success}")
        print(f"     è§‚æµ‹æ¯”ä¾‹: {self.n_success/self.n_trials:.4f}")
        
        print(f"\n  âœ¨ åéªŒåˆ†å¸ƒ: Beta({self.posterior_alpha}, {self.posterior_beta})")
        posterior_mean = self.posterior_alpha / (self.posterior_alpha + self.posterior_beta)
        posterior_mode = (self.posterior_alpha - 1) / (self.posterior_alpha + self.posterior_beta - 2)
        posterior_var = (self.posterior_alpha * self.posterior_beta) / \
                       ((self.posterior_alpha + self.posterior_beta)**2 * 
                        (self.posterior_alpha + self.posterior_beta + 1))
        
        print(f"\n  ğŸ“ˆ åéªŒç»Ÿè®¡:")
        print(f"     åéªŒå‡å€¼: {posterior_mean:.4f}")
        print(f"     åéªŒä¼—æ•°: {posterior_mode:.4f}")
        print(f"     åéªŒæ ‡å‡†å·®: {np.sqrt(posterior_var):.4f}")
        
        ci_lower, ci_upper = self.credible_interval(0.95)
        print(f"     95% å¯ä¿¡åŒºé—´: [{ci_lower:.4f}, {ci_upper:.4f}]")
        print("="*60)
    
    def credible_interval(self, level=0.95):
        """è®¡ç®—åéªŒå¯ä¿¡åŒºé—´"""
        alpha_ci = 1 - level
        lower = stats.beta.ppf(alpha_ci/2, self.posterior_alpha, self.posterior_beta)
        upper = stats.beta.ppf(1-alpha_ci/2, self.posterior_alpha, self.posterior_beta)
        return lower, upper
    
    def posterior_pdf(self, p):
        """åéªŒæ¦‚ç‡å¯†åº¦"""
        return stats.beta.pdf(p, self.posterior_alpha, self.posterior_beta)
    
    def prior_pdf(self, p):
        """å…ˆéªŒæ¦‚ç‡å¯†åº¦"""
        return stats.beta.pdf(p, self.prior_alpha, self.prior_beta)
    
    def probability_greater_than(self, threshold):
        """P(p > threshold | data)"""
        prob = 1 - stats.beta.cdf(threshold, self.posterior_alpha, self.posterior_beta)
        if self.verbose:
            print(f"\n  P(p > {threshold}) = {prob:.4f}")
        return prob
    
    def plot_distributions(self, save_path=None):
        """ç»˜åˆ¶å…ˆéªŒå’ŒåéªŒåˆ†å¸ƒ"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        p = np.linspace(0.001, 0.999, 500)
        
        # å…ˆéªŒ
        prior = self.prior_pdf(p)
        ax.plot(p, prior, color=PlotStyleConfig.COLORS['primary'], 
               linewidth=2.5, linestyle='--', label=f'å…ˆéªŒ Beta({self.prior_alpha}, {self.prior_beta})')
        ax.fill_between(p, prior, alpha=0.2, color=PlotStyleConfig.COLORS['primary'])
        
        # åéªŒ
        posterior = self.posterior_pdf(p)
        ax.plot(p, posterior, color=PlotStyleConfig.COLORS['danger'], 
               linewidth=2.5, label=f'åéªŒ Beta({self.posterior_alpha}, {self.posterior_beta})')
        ax.fill_between(p, posterior, alpha=0.3, color=PlotStyleConfig.COLORS['danger'])
        
        # æ ‡è®°å¯ä¿¡åŒºé—´
        ci_lower, ci_upper = self.credible_interval(0.95)
        ax.axvline(ci_lower, color=PlotStyleConfig.COLORS['accent'], linestyle=':', linewidth=2)
        ax.axvline(ci_upper, color=PlotStyleConfig.COLORS['accent'], linestyle=':', linewidth=2)
        
        # æ ‡è®°è§‚æµ‹æ¯”ä¾‹
        obs_rate = self.n_success / self.n_trials
        ax.axvline(obs_rate, color='gray', linestyle='--', linewidth=1.5,
                  label=f'è§‚æµ‹æ¯”ä¾‹ = {obs_rate:.3f}')
        
        ax.set_xlabel('æˆåŠŸæ¦‚ç‡ p', fontsize=12, fontweight='bold')
        ax.set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=12, fontweight='bold')
        ax.set_title('Beta-äºŒé¡¹è´å¶æ–¯æ¨æ–­', fontsize=14, fontweight='bold', pad=15)
        ax.legend(loc='upper right')
        ax.set_xlim(0, 1)
        
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            saver = FigureSaver(os.path.dirname(save_path))
            saver.save(fig, os.path.basename(save_path).split('.')[0])
        
        return fig, ax


class MCMCBayesian(BayesianInference):
    """
    MCMCè´å¶æ–¯æ¨æ–­ï¼ˆMetropolis-Hastingsç®—æ³•ï¼‰
    
    é€‚ç”¨äºæ— å…±è½­å…ˆéªŒæˆ–å¤æ‚åéªŒåˆ†å¸ƒçš„æƒ…å†µ
    """
    
    def __init__(self, log_likelihood_func, log_prior_func, 
                 proposal_std=0.5, n_samples=10000, burn_in=1000, verbose=True):
        """
        åˆå§‹åŒ–MCMCé‡‡æ ·å™¨
        
        :param log_likelihood_func: å¯¹æ•°ä¼¼ç„¶å‡½æ•° f(theta, data) -> log p(data|theta)
        :param log_prior_func: å¯¹æ•°å…ˆéªŒå‡½æ•° f(theta) -> log p(theta)
        :param proposal_std: æè®®åˆ†å¸ƒæ ‡å‡†å·®
        :param n_samples: é‡‡æ ·æ•°é‡
        :param burn_in: é¢„çƒ§æœŸæ ·æœ¬æ•°
        """
        super().__init__(verbose)
        self.log_likelihood = log_likelihood_func
        self.log_prior = log_prior_func
        self.proposal_std = proposal_std
        self.n_samples = n_samples
        self.burn_in = burn_in
        
        self.samples = None
        self.acceptance_rate = None
        
    def log_posterior(self, theta, data):
        """å¯¹æ•°åéªŒï¼ˆéå½’ä¸€åŒ–ï¼‰"""
        return self.log_likelihood(theta, data) + self.log_prior(theta)
    
    def fit(self, data, initial_theta=None):
        """
        ä½¿ç”¨MCMCé‡‡æ ·åéªŒåˆ†å¸ƒ
        
        :param data: è§‚æµ‹æ•°æ®
        :param initial_theta: åˆå§‹å‚æ•°å€¼
        :return: self
        """
        self.data = data
        n_dims = 1 if initial_theta is None or np.isscalar(initial_theta) else len(initial_theta)
        
        if initial_theta is None:
            current = np.zeros(n_dims)
        else:
            current = np.atleast_1d(initial_theta).astype(float)
        
        samples = []
        accepted = 0
        
        current_log_post = self.log_posterior(current, data)
        
        for i in range(self.n_samples + self.burn_in):
            # æè®®æ–°çŠ¶æ€
            proposal = current + np.random.normal(0, self.proposal_std, n_dims)
            proposal_log_post = self.log_posterior(proposal, data)
            
            # Metropolis-Hastingsæ¥å—ç‡
            log_alpha = proposal_log_post - current_log_post
            
            if np.log(np.random.random()) < log_alpha:
                current = proposal
                current_log_post = proposal_log_post
                if i >= self.burn_in:
                    accepted += 1
            
            if i >= self.burn_in:
                samples.append(current.copy())
        
        self.samples = np.array(samples)
        self.acceptance_rate = accepted / self.n_samples
        
        if self.verbose:
            self._print_results()
            
        return self
    
    def _print_results(self):
        """æ‰“å°MCMCç»“æœ"""
        self._print_header("MCMC è´å¶æ–¯æ¨æ–­")
        print(f"\n  ğŸ“Œ é‡‡æ ·è®¾ç½®:")
        print(f"     æ€»æ ·æœ¬æ•°: {self.n_samples}")
        print(f"     é¢„çƒ§æœŸ: {self.burn_in}")
        print(f"     æ¥å—ç‡: {self.acceptance_rate*100:.1f}%")
        
        print(f"\n  ğŸ“ˆ åéªŒç»Ÿè®¡:")
        if self.samples.ndim == 1 or self.samples.shape[1] == 1:
            samples = self.samples.flatten()
            print(f"     åéªŒå‡å€¼: {np.mean(samples):.4f}")
            print(f"     åéªŒä¸­ä½æ•°: {np.median(samples):.4f}")
            print(f"     åéªŒæ ‡å‡†å·®: {np.std(samples):.4f}")
            print(f"     95% CI: [{np.percentile(samples, 2.5):.4f}, {np.percentile(samples, 97.5):.4f}]")
        else:
            for i in range(self.samples.shape[1]):
                print(f"\n     å‚æ•° {i+1}:")
                print(f"       å‡å€¼: {np.mean(self.samples[:, i]):.4f}")
                print(f"       95% CI: [{np.percentile(self.samples[:, i], 2.5):.4f}, "
                      f"{np.percentile(self.samples[:, i], 97.5):.4f}]")
        print("="*60)
    
    def credible_interval(self, param_idx=0, level=0.95):
        """è®¡ç®—å¯ä¿¡åŒºé—´"""
        alpha = 1 - level
        if self.samples.ndim == 1:
            samples = self.samples
        else:
            samples = self.samples[:, param_idx]
        return np.percentile(samples, [alpha/2*100, (1-alpha/2)*100])
    
    def plot_trace(self, param_idx=0, save_path=None):
        """ç»˜åˆ¶è¿½è¸ªå›¾å’ŒåéªŒåˆ†å¸ƒ"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        if self.samples.ndim == 1:
            samples = self.samples
        else:
            samples = self.samples[:, param_idx]
        
        # è¿½è¸ªå›¾
        axes[0].plot(samples, color=PlotStyleConfig.COLORS['primary'], 
                    alpha=0.7, linewidth=0.5)
        axes[0].axhline(np.mean(samples), color=PlotStyleConfig.COLORS['danger'],
                       linestyle='--', linewidth=2, label=f'å‡å€¼ = {np.mean(samples):.3f}')
        axes[0].set_xlabel('è¿­ä»£æ¬¡æ•°', fontweight='bold')
        axes[0].set_ylabel('å‚æ•°å€¼', fontweight='bold')
        axes[0].set_title('MCMC è¿½è¸ªå›¾', fontsize=12, fontweight='bold')
        axes[0].legend()
        
        # åéªŒåˆ†å¸ƒ
        axes[1].hist(samples, bins=50, density=True, 
                    color=PlotStyleConfig.COLORS['primary'], alpha=0.7, edgecolor='white')
        
        # KDEæ›²çº¿
        from scipy.stats import gaussian_kde
        kde = gaussian_kde(samples)
        x_range = np.linspace(samples.min(), samples.max(), 200)
        axes[1].plot(x_range, kde(x_range), color=PlotStyleConfig.COLORS['danger'],
                    linewidth=2.5, label='KDE')
        
        # å¯ä¿¡åŒºé—´
        ci = self.credible_interval(param_idx, 0.95)
        axes[1].axvline(ci[0], color=PlotStyleConfig.COLORS['accent'], 
                       linestyle=':', linewidth=2)
        axes[1].axvline(ci[1], color=PlotStyleConfig.COLORS['accent'], 
                       linestyle=':', linewidth=2, label='95% CI')
        
        axes[1].set_xlabel('å‚æ•°å€¼', fontweight='bold')
        axes[1].set_ylabel('æ¦‚ç‡å¯†åº¦', fontweight='bold')
        axes[1].set_title('åéªŒåˆ†å¸ƒ', fontsize=12, fontweight='bold')
        axes[1].legend()
        
        for ax in axes:
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            saver = FigureSaver(os.path.dirname(save_path))
            saver.save(fig, os.path.basename(save_path).split('.')[0])
        
        return fig, axes


class BayesianParameterEstimation:
    """
    è´å¶æ–¯å‚æ•°åæ¼” - é€†é—®é¢˜æ±‚è§£
    
    åœºæ™¯ï¼šç»™å®šè§‚æµ‹æ•°æ®å’Œæ­£å‘æ¨¡å‹ï¼Œåæ¨æ¨¡å‹å‚æ•°
    
    åº”ç”¨ï¼š
    - é€šè¿‡ç£¨æŸç¨‹åº¦æ¨æµ‹äººæµé‡
    - é€šè¿‡æ±¡æŸ“æµ“åº¦æ¨æµ‹æ±¡æŸ“æºå¼ºåº¦
    - é€šè¿‡ä¿¡å·æ¨æµ‹ç³»ç»Ÿå‚æ•°
    """
    
    def __init__(self, forward_model, param_bounds, noise_std=1.0, verbose=True):
        """
        åˆå§‹åŒ–å‚æ•°åæ¼”å™¨
        
        :param forward_model: æ­£å‘æ¨¡å‹å‡½æ•° f(params) -> predictions
        :param param_bounds: å‚æ•°èŒƒå›´åˆ—è¡¨ [(low1, high1), (low2, high2), ...]
        :param noise_std: è§‚æµ‹å™ªå£°æ ‡å‡†å·®
        """
        self.forward_model = forward_model
        self.param_bounds = param_bounds
        self.noise_std = noise_std
        self.verbose = verbose
        self.n_params = len(param_bounds)
        
        self.samples = None
        self.map_estimate = None
        self.posterior_mean = None
        
    def log_likelihood(self, params, observations):
        """å¯¹æ•°ä¼¼ç„¶ï¼šå‡è®¾é«˜æ–¯å™ªå£°"""
        try:
            predictions = self.forward_model(params)
            residuals = observations - predictions
            return -0.5 * np.sum((residuals / self.noise_std)**2)
        except:
            return -np.inf
    
    def log_prior(self, params):
        """å‡åŒ€å…ˆéªŒï¼ˆåœ¨è¾¹ç•Œå†…ï¼‰"""
        for i, (low, high) in enumerate(self.param_bounds):
            if params[i] < low or params[i] > high:
                return -np.inf
        return 0.0
    
    def fit(self, observations, n_samples=10000, proposal_stds=None):
        """
        æ‰§è¡Œè´å¶æ–¯å‚æ•°åæ¼”
        
        :param observations: è§‚æµ‹æ•°æ®
        :param n_samples: MCMCæ ·æœ¬æ•°
        :param proposal_stds: å„å‚æ•°çš„æè®®æ ‡å‡†å·®
        """
        if proposal_stds is None:
            proposal_stds = [(b[1]-b[0])/10 for b in self.param_bounds]
        
        # åˆå§‹å€¼ï¼šå‚æ•°èŒƒå›´ä¸­ç‚¹
        current = np.array([(b[0]+b[1])/2 for b in self.param_bounds])
        
        samples = []
        burn_in = n_samples // 5
        accepted = 0
        
        current_log_post = self.log_likelihood(current, observations) + self.log_prior(current)
        
        for i in range(n_samples + burn_in):
            # æè®®
            proposal = current + np.random.normal(0, proposal_stds)
            proposal_log_post = self.log_likelihood(proposal, observations) + self.log_prior(proposal)
            
            # æ¥å—/æ‹’ç»
            log_alpha = proposal_log_post - current_log_post
            if np.log(np.random.random()) < log_alpha:
                current = proposal
                current_log_post = proposal_log_post
                if i >= burn_in:
                    accepted += 1
            
            if i >= burn_in:
                samples.append(current.copy())
        
        self.samples = np.array(samples)
        self.posterior_mean = np.mean(self.samples, axis=0)
        self.map_estimate = self.samples[np.argmax([self.log_likelihood(s, observations) 
                                                     for s in self.samples])]
        
        if self.verbose:
            self._print_results(accepted / n_samples)
            
        return self
    
    def _print_results(self, acceptance_rate):
        """æ‰“å°åæ¼”ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š è´å¶æ–¯å‚æ•°åæ¼”ç»“æœ")
        print("="*60)
        print(f"\n  æ¥å—ç‡: {acceptance_rate*100:.1f}%")
        print(f"\n  å‚æ•°ä¼°è®¡:")
        print("  " + "-"*50)
        print(f"  {'å‚æ•°':^8} {'åéªŒå‡å€¼':^12} {'MAPä¼°è®¡':^12} {'95% CI':^20}")
        print("  " + "-"*50)
        
        for i in range(self.n_params):
            mean = self.posterior_mean[i]
            map_val = self.map_estimate[i]
            ci = np.percentile(self.samples[:, i], [2.5, 97.5])
            print(f"  Î¸{i+1:^6} {mean:^12.4f} {map_val:^12.4f} [{ci[0]:.4f}, {ci[1]:.4f}]")
        
        print("  " + "-"*50)
        print("="*60)
    
    def plot_corner(self, param_names=None, save_path=None):
        """ç»˜åˆ¶è§’å›¾ï¼ˆå‚æ•°è”åˆåˆ†å¸ƒï¼‰"""
        n = self.n_params
        
        if param_names is None:
            param_names = [f'Î¸{i+1}' for i in range(n)]
        
        fig, axes = plt.subplots(n, n, figsize=(3*n, 3*n))
        
        for i in range(n):
            for j in range(n):
                ax = axes[i, j]
                
                if i == j:
                    # å¯¹è§’çº¿ï¼šè¾¹ç¼˜åˆ†å¸ƒ
                    ax.hist(self.samples[:, i], bins=30, density=True,
                           color=PlotStyleConfig.COLORS['primary'], alpha=0.7)
                    ax.axvline(self.posterior_mean[i], color='red', linestyle='--')
                elif i > j:
                    # ä¸‹ä¸‰è§’ï¼šæ•£ç‚¹å›¾
                    ax.scatter(self.samples[:, j], self.samples[:, i], 
                              alpha=0.1, s=1, c=PlotStyleConfig.COLORS['primary'])
                    ax.axhline(self.posterior_mean[i], color='red', linestyle='--', alpha=0.5)
                    ax.axvline(self.posterior_mean[j], color='red', linestyle='--', alpha=0.5)
                else:
                    # ä¸Šä¸‰è§’ï¼šéšè—
                    ax.set_visible(False)
                
                if i == n-1:
                    ax.set_xlabel(param_names[j], fontweight='bold')
                if j == 0 and i != 0:
                    ax.set_ylabel(param_names[i], fontweight='bold')
        
        plt.suptitle('å‚æ•°åéªŒè”åˆåˆ†å¸ƒ', fontsize=14, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        if save_path:
            saver = FigureSaver(os.path.dirname(save_path))
            saver.save(fig, os.path.basename(save_path).split('.')[0])
        
        return fig, axes


if __name__ == "__main__":
    print("="*60)
    print("ğŸ“Š è´å¶æ–¯æ¨æ–­æ¨¡å‹æ¼”ç¤º")
    print("="*60)
    
    # ================== ç¤ºä¾‹1: æ­£æ€-æ­£æ€æ¨æ–­ ==================
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: æ­£æ€-æ­£æ€è´å¶æ–¯æ¨æ–­")
    print("="*60)
    
    np.random.seed(42)
    true_mu = 75
    data = np.random.normal(true_mu, 10, 50)  # çœŸå®å‡å€¼75
    
    # å…ˆéªŒï¼šè®¤ä¸ºå‡å€¼åœ¨70å·¦å³ï¼Œä½†ä¸å¤ªç¡®å®š
    bayes = NormalNormalBayes(prior_mu=70, prior_tau=20, known_sigma=10)
    bayes.fit(data)
    
    fig1, axes1 = bayes.plot_distributions()
    plt.show()
    
    # åºåˆ—æ›´æ–°æ¼”ç¤º
    data_batches = [
        np.random.normal(75, 10, 10),
        np.random.normal(75, 10, 20),
        np.random.normal(75, 10, 30),
    ]
    fig2, ax2 = bayes.plot_updating(data_batches)
    plt.show()
    
    # ================== ç¤ºä¾‹2: Beta-äºŒé¡¹æ¨æ–­ ==================
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: Beta-äºŒé¡¹è´å¶æ–¯æ¨æ–­ï¼ˆè½¬åŒ–ç‡ä¼°è®¡ï¼‰")
    print("="*60)
    
    # åœºæ™¯ï¼šç½‘ç«™A/Bæµ‹è¯•ï¼Œ100æ¬¡è®¿é—®ä¸­æœ‰23æ¬¡è½¬åŒ–
    beta_bayes = BetaBinomialBayes(prior_alpha=2, prior_beta=8)  # å…ˆéªŒè®¤ä¸ºè½¬åŒ–ç‡çº¦20%
    beta_bayes.fit(n_success=23, n_trials=100)
    
    # è®¡ç®—æ¦‚ç‡
    beta_bayes.probability_greater_than(0.20)  # P(è½¬åŒ–ç‡>20%)
    
    fig3, ax3 = beta_bayes.plot_distributions()
    plt.show()
    
    # ================== ç¤ºä¾‹3: å‚æ•°åæ¼”ï¼ˆé€†é—®é¢˜ï¼‰==================
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: è´å¶æ–¯å‚æ•°åæ¼”ï¼ˆç”±æœæ¨å› ï¼‰")
    print("="*60)
    
    # åœºæ™¯ï¼šç£¨æŸæ¨¡å‹ wear = k * flow * time
    # å·²çŸ¥æ—¶é—´å’Œç£¨æŸé‡ï¼Œåæ¨äººæµé‡å’Œç£¨æŸç³»æ•°
    
    def wear_model(params):
        """æ­£å‘æ¨¡å‹ï¼šç£¨æŸé‡ = k * flow * time"""
        k, flow = params
        time = np.array([1, 2, 3, 4, 5])  # 5å¹´è§‚æµ‹
        return k * flow * time
    
    # ç”Ÿæˆæ¨¡æ‹Ÿè§‚æµ‹æ•°æ®ï¼ˆçœŸå®å‚æ•°: k=0.01, flow=1000ï¼‰
    true_params = [0.01, 1000]
    true_wear = wear_model(true_params)
    observed_wear = true_wear + np.random.normal(0, 0.5, len(true_wear))
    
    print(f"è§‚æµ‹ç£¨æŸé‡: {observed_wear}")
    print(f"çœŸå®å‚æ•°: k={true_params[0]}, flow={true_params[1]}")
    
    # è´å¶æ–¯åæ¼”
    inverter = BayesianParameterEstimation(
        forward_model=wear_model,
        param_bounds=[(0.001, 0.1), (100, 5000)],  # kå’Œflowçš„èŒƒå›´
        noise_std=0.5
    )
    inverter.fit(observed_wear, n_samples=5000)
    
    fig4, axes4 = inverter.plot_corner(param_names=['ç£¨æŸç³»æ•°k', 'äººæµé‡flow'])
    plt.show()
    
    print("\nâœ… è´å¶æ–¯æ¨æ–­æ¨¡å‹æ¼”ç¤ºå®Œæˆ!")
