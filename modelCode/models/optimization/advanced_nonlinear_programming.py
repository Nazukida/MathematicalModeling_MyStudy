"""
============================================================
é«˜çº§éçº¿æ€§è§„åˆ’æ¨¡å‹ (Advanced Nonlinear Programming)
é€‚ç”¨äºç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› (MCM/ICM)
============================================================
åŠŸèƒ½ï¼šéçº¿æ€§ä¼˜åŒ–ã€çº¦æŸå¤„ç†ã€çµæ•åº¦åˆ†æã€å®Œæ•´å¯è§†åŒ–
ç‰¹ç‚¹ï¼šå®Œå¤‡çš„æ•°æ®é¢„å¤„ç† + æ¨¡å‹æ±‚è§£ + ç»“æœå¯è§†åŒ–ä¸‰ä½ä¸€ä½“

ä½¿ç”¨åœºæ™¯ï¼š
- æŠ•èµ„ç»„åˆä¼˜åŒ–ï¼ˆäºŒæ¬¡è§„åˆ’ï¼‰
- ç”Ÿäº§è®¡åˆ’ä¼˜åŒ–
- æ›²çº¿æ‹Ÿåˆä¸å›å½’
- å·¥ç¨‹è®¾è®¡ä¼˜åŒ–

ä½œè€…ï¼šMCM/ICM Team
æ—¥æœŸï¼š2026å¹´1æœˆ
============================================================
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from scipy.optimize import minimize, differential_evolution
from scipy.stats import zscore
from typing import Callable, List, Dict, Tuple, Optional, Union
import warnings
from datetime import datetime
import os

warnings.filterwarnings('ignore')

# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå›¾è¡¨é…ç½®
# ============================================================

class NLPPlotConfig:
    """éçº¿æ€§è§„åˆ’å¯è§†åŒ–é…ç½®"""
    
    COLORS = {
        'optimal': '#E94F37',       # æœ€ä¼˜ç‚¹é¢œè‰²
        'feasible': '#2E86AB',      # å¯è¡ŒåŸŸé¢œè‰²
        'constraint': '#F18F01',    # çº¦æŸçº¿é¢œè‰²
        'contour': '#6B4C9A',       # ç­‰é«˜çº¿é¢œè‰²
        'path': '#27AE60',          # è¿­ä»£è·¯å¾„é¢œè‰²
        'grid': '#E0E0E0'
    }
    
    @staticmethod
    def setup():
        plt.style.use('seaborn-v0_8-whitegrid')
        rcParams['figure.figsize'] = (12, 8)
        rcParams['figure.dpi'] = 100
        rcParams['savefig.dpi'] = 300
        rcParams['font.size'] = 11
        rcParams['axes.titlesize'] = 14
        rcParams['axes.labelsize'] = 12
        rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        rcParams['axes.unicode_minus'] = False

NLPPlotConfig.setup()


# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†æ¨¡å—
# ============================================================

class NLPDataPreprocessor:
    """
    éçº¿æ€§è§„åˆ’æ•°æ®é¢„å¤„ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. æ•°æ®æ¸…æ´—ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼‰
    2. æ•°æ®æ ‡å‡†åŒ–
    3. å‚æ•°èŒƒå›´ä¼°è®¡
    4. åˆå§‹ç‚¹é€‰æ‹©
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.processing_log = []
    
    def _log(self, message: str):
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.processing_log.append(log_entry)
        if self.verbose:
            print(log_entry)
    
    def clean_data(self, data: Union[np.ndarray, pd.DataFrame], 
                   method: str = 'median') -> np.ndarray:
        """
        æ•°æ®æ¸…æ´—
        
        :param data: è¾“å…¥æ•°æ®
        :param method: ç¼ºå¤±å€¼å¡«å……æ–¹æ³• ('mean', 'median', 'drop')
        :return: æ¸…æ´—åçš„æ•°æ®
        """
        self._log("å¼€å§‹æ•°æ®æ¸…æ´—...")
        
        if isinstance(data, pd.DataFrame):
            data = data.values
        
        data = np.array(data, dtype=float)
        
        # å¤„ç†ç¼ºå¤±å€¼
        nan_count = np.sum(np.isnan(data))
        if nan_count > 0:
            self._log(f"  å‘ç° {nan_count} ä¸ªç¼ºå¤±å€¼")
            if method == 'mean':
                col_means = np.nanmean(data, axis=0)
                for i in range(data.shape[1]):
                    data[np.isnan(data[:, i]), i] = col_means[i]
            elif method == 'median':
                col_medians = np.nanmedian(data, axis=0)
                for i in range(data.shape[1]):
                    data[np.isnan(data[:, i]), i] = col_medians[i]
            elif method == 'drop':
                data = data[~np.any(np.isnan(data), axis=1)]
            self._log(f"  ä½¿ç”¨ {method} æ–¹æ³•å¤„ç†å®Œæˆ")
        else:
            self._log("  æœªå‘ç°ç¼ºå¤±å€¼")
        
        return data
    
    def detect_outliers(self, data: np.ndarray, 
                        method: str = 'zscore', 
                        threshold: float = 3.0) -> Tuple[np.ndarray, np.ndarray]:
        """
        å¼‚å¸¸å€¼æ£€æµ‹
        
        :param method: 'zscore' æˆ– 'iqr'
        :param threshold: é˜ˆå€¼
        :return: (æ¸…æ´—åæ•°æ®, å¼‚å¸¸å€¼ç´¢å¼•)
        """
        self._log(f"å¼‚å¸¸å€¼æ£€æµ‹ (æ–¹æ³•: {method}, é˜ˆå€¼: {threshold})...")
        
        if method == 'zscore':
            z_scores = np.abs(zscore(data, axis=0, nan_policy='omit'))
            outlier_mask = np.any(z_scores > threshold, axis=1)
        elif method == 'iqr':
            Q1 = np.percentile(data, 25, axis=0)
            Q3 = np.percentile(data, 75, axis=0)
            IQR = Q3 - Q1
            lower = Q1 - threshold * IQR
            upper = Q3 + threshold * IQR
            outlier_mask = np.any((data < lower) | (data > upper), axis=1)
        
        outlier_indices = np.where(outlier_mask)[0]
        clean_data = data[~outlier_mask]
        
        self._log(f"  æ£€æµ‹åˆ° {len(outlier_indices)} ä¸ªå¼‚å¸¸æ ·æœ¬")
        
        return clean_data, outlier_indices
    
    def normalize(self, data: np.ndarray, 
                  method: str = 'minmax') -> Tuple[np.ndarray, Dict]:
        """
        æ•°æ®æ ‡å‡†åŒ–
        
        :param method: 'minmax', 'zscore', 'robust'
        :return: (æ ‡å‡†åŒ–æ•°æ®, å‚æ•°å­—å…¸ç”¨äºåæ ‡å‡†åŒ–)
        """
        self._log(f"æ•°æ®æ ‡å‡†åŒ– (æ–¹æ³•: {method})...")
        
        params = {'method': method}
        
        if method == 'minmax':
            min_vals = np.min(data, axis=0)
            max_vals = np.max(data, axis=0)
            range_vals = max_vals - min_vals
            range_vals[range_vals == 0] = 1  # é¿å…é™¤é›¶
            normalized = (data - min_vals) / range_vals
            params['min'] = min_vals
            params['max'] = max_vals
        elif method == 'zscore':
            mean_vals = np.mean(data, axis=0)
            std_vals = np.std(data, axis=0)
            std_vals[std_vals == 0] = 1
            normalized = (data - mean_vals) / std_vals
            params['mean'] = mean_vals
            params['std'] = std_vals
        elif method == 'robust':
            median_vals = np.median(data, axis=0)
            Q1 = np.percentile(data, 25, axis=0)
            Q3 = np.percentile(data, 75, axis=0)
            IQR = Q3 - Q1
            IQR[IQR == 0] = 1
            normalized = (data - median_vals) / IQR
            params['median'] = median_vals
            params['IQR'] = IQR
        
        return normalized, params
    
    def estimate_bounds(self, data: np.ndarray, 
                        expand_ratio: float = 0.2) -> List[Tuple[float, float]]:
        """
        åŸºäºæ•°æ®ä¼°è®¡å˜é‡è¾¹ç•Œ
        
        :param expand_ratio: è¾¹ç•Œæ‰©å±•æ¯”ä¾‹
        :return: è¾¹ç•Œåˆ—è¡¨ [(min1, max1), (min2, max2), ...]
        """
        self._log("ä¼°è®¡å˜é‡è¾¹ç•Œ...")
        
        bounds = []
        for i in range(data.shape[1]):
            col = data[:, i]
            min_val, max_val = np.min(col), np.max(col)
            range_val = max_val - min_val
            lower = min_val - expand_ratio * range_val
            upper = max_val + expand_ratio * range_val
            bounds.append((lower, upper))
            self._log(f"  å˜é‡ x{i+1}: [{lower:.4f}, {upper:.4f}]")
        
        return bounds
    
    def generate_initial_points(self, bounds: List[Tuple], 
                                n_points: int = 10,
                                method: str = 'random') -> np.ndarray:
        """
        ç”Ÿæˆå¤šä¸ªåˆå§‹ç‚¹ç”¨äºå¤šèµ·ç‚¹ä¼˜åŒ–
        
        :param method: 'random', 'latin', 'grid'
        :return: åˆå§‹ç‚¹æ•°ç»„ (n_points, n_dim)
        """
        n_dim = len(bounds)
        
        if method == 'random':
            points = np.zeros((n_points, n_dim))
            for i, (lb, ub) in enumerate(bounds):
                points[:, i] = np.random.uniform(lb, ub, n_points)
        elif method == 'latin':
            # æ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·
            points = np.zeros((n_points, n_dim))
            for i, (lb, ub) in enumerate(bounds):
                perm = np.random.permutation(n_points)
                points[:, i] = lb + (perm + np.random.rand(n_points)) * (ub - lb) / n_points
        elif method == 'grid':
            # ç½‘æ ¼é‡‡æ ·
            n_per_dim = max(2, int(n_points ** (1/n_dim)))
            grids = [np.linspace(lb, ub, n_per_dim) for lb, ub in bounds]
            mesh = np.meshgrid(*grids)
            points = np.column_stack([m.ravel() for m in mesh])[:n_points]
        
        self._log(f"ç”Ÿæˆ {len(points)} ä¸ªåˆå§‹ç‚¹ (æ–¹æ³•: {method})")
        return points


# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šéçº¿æ€§è§„åˆ’æ±‚è§£å™¨
# ============================================================

class NonlinearProgrammingSolver:
    """
    éçº¿æ€§è§„åˆ’æ±‚è§£å™¨
    
    æ”¯æŒï¼š
    1. æ— çº¦æŸä¼˜åŒ–
    2. ç­‰å¼çº¦æŸ
    3. ä¸ç­‰å¼çº¦æŸ
    4. è¾¹ç•Œçº¦æŸ
    5. å¤šèµ·ç‚¹å…¨å±€ä¼˜åŒ–
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.history = []  # è®°å½•è¿­ä»£å†å²
        self.result = None
        
    def _callback(self, x):
        """è¿­ä»£å›è°ƒå‡½æ•°ï¼Œè®°å½•ä¼˜åŒ–è·¯å¾„"""
        self.history.append(x.copy())
    
    def solve(self, 
              objective: Callable,
              x0: np.ndarray,
              bounds: Optional[List[Tuple]] = None,
              constraints: Optional[List[Dict]] = None,
              method: str = 'SLSQP',
              options: Optional[Dict] = None) -> Dict:
        """
        æ±‚è§£éçº¿æ€§è§„åˆ’é—®é¢˜
        
        :param objective: ç›®æ ‡å‡½æ•° f(x) -> float
        :param x0: åˆå§‹ç‚¹
        :param bounds: å˜é‡è¾¹ç•Œ [(min, max), ...]
        :param constraints: çº¦æŸæ¡ä»¶åˆ—è¡¨
            [{'type': 'ineq', 'fun': g}, {'type': 'eq', 'fun': h}]
            ä¸ç­‰å¼çº¦æŸ: g(x) >= 0
            ç­‰å¼çº¦æŸ: h(x) = 0
        :param method: 'SLSQP', 'trust-constr', 'COBYLA', 'L-BFGS-B'
        :param options: æ±‚è§£å™¨é€‰é¡¹
        :return: ç»“æœå­—å…¸
        """
        self.history = []
        
        if self.verbose:
            print("\n" + "="*60)
            print("   éçº¿æ€§è§„åˆ’æ±‚è§£å™¨ (NLP Solver)")
            print("="*60)
            print(f"  æ–¹æ³•: {method}")
            print(f"  å˜é‡ç»´åº¦: {len(x0)}")
            print(f"  åˆå§‹ç‚¹: {x0}")
        
        default_options = {
            'maxiter': 1000,
            'ftol': 1e-8,
            'disp': False
        }
        if options:
            default_options.update(options)
        
        # è°ƒç”¨scipyä¼˜åŒ–å™¨
        result = minimize(
            objective,
            x0,
            method=method,
            bounds=bounds,
            constraints=constraints or [],
            options=default_options,
            callback=self._callback
        )
        
        self.result = {
            'success': result.success,
            'x': result.x,
            'fun': result.fun,
            'message': result.message,
            'nit': result.nit if hasattr(result, 'nit') else len(self.history),
            'nfev': result.nfev if hasattr(result, 'nfev') else 0,
            'history': np.array(self.history) if self.history else None
        }
        
        if self.verbose:
            self._print_result()
        
        return self.result
    
    def multistart_solve(self,
                         objective: Callable,
                         bounds: List[Tuple],
                         n_starts: int = 10,
                         constraints: Optional[List[Dict]] = None,
                         method: str = 'SLSQP') -> Dict:
        """
        å¤šèµ·ç‚¹å…¨å±€ä¼˜åŒ–
        
        :param n_starts: èµ·å§‹ç‚¹æ•°é‡
        :return: æœ€ä¼˜ç»“æœ
        """
        if self.verbose:
            print(f"\nå¤šèµ·ç‚¹ä¼˜åŒ–: {n_starts} ä¸ªèµ·å§‹ç‚¹")
        
        preprocessor = NLPDataPreprocessor(verbose=False)
        initial_points = preprocessor.generate_initial_points(bounds, n_starts, 'latin')
        
        best_result = None
        all_results = []
        
        for i, x0 in enumerate(initial_points):
            self.history = []
            result = self.solve(objective, x0, bounds, constraints, method)
            all_results.append(result)
            
            if result['success']:
                if best_result is None or result['fun'] < best_result['fun']:
                    best_result = result
        
        if best_result is None and all_results:
            best_result = min(all_results, key=lambda r: r['fun'])
        
        if self.verbose:
            print(f"\næœ€ä¼˜è§£æ¥è‡ªç¬¬ {all_results.index(best_result)+1} ä¸ªèµ·å§‹ç‚¹")
        
        self.result = best_result
        return best_result
    
    def global_solve(self,
                     objective: Callable,
                     bounds: List[Tuple],
                     constraints: Optional[List[Dict]] = None,
                     maxiter: int = 1000) -> Dict:
        """
        å…¨å±€ä¼˜åŒ–ï¼ˆå·®åˆ†è¿›åŒ–ç®—æ³•ï¼‰
        
        é€‚ç”¨äºéå‡¸é—®é¢˜æˆ–å­˜åœ¨å¤šä¸ªå±€éƒ¨æœ€ä¼˜çš„æƒ…å†µ
        """
        if self.verbose:
            print("\nå…¨å±€ä¼˜åŒ– (å·®åˆ†è¿›åŒ–ç®—æ³•)")
        
        # å·®åˆ†è¿›åŒ–ä¸ç›´æ¥æ”¯æŒçº¦æŸï¼Œä½¿ç”¨æƒ©ç½šå‡½æ•°æ³•
        if constraints:
            penalty_weight = 1e6
            
            def penalized_objective(x):
                val = objective(x)
                for con in constraints:
                    c_val = con['fun'](x)
                    if con['type'] == 'ineq':
                        val += penalty_weight * max(0, -c_val) ** 2
                    elif con['type'] == 'eq':
                        val += penalty_weight * c_val ** 2
                return val
        else:
            penalized_objective = objective
        
        result = differential_evolution(
            penalized_objective,
            bounds,
            maxiter=maxiter,
            seed=42,
            polish=True
        )
        
        self.result = {
            'success': result.success,
            'x': result.x,
            'fun': objective(result.x),  # è¿”å›åŸå§‹ç›®æ ‡å€¼
            'message': result.message,
            'nit': result.nit,
            'nfev': result.nfev,
            'history': None
        }
        
        if self.verbose:
            self._print_result()
        
        return self.result
    
    def _print_result(self):
        """æ‰“å°æ±‚è§£ç»“æœ"""
        r = self.result
        print("\n" + "-"*50)
        print("ğŸ“Š æ±‚è§£ç»“æœ")
        print("-"*50)
        print(f"  çŠ¶æ€: {'âœ… æˆåŠŸ' if r['success'] else 'âŒ å¤±è´¥'}")
        print(f"  æœ€ä¼˜è§£: {r['x']}")
        print(f"  æœ€ä¼˜ç›®æ ‡å€¼: {r['fun']:.6f}")
        print(f"  è¿­ä»£æ¬¡æ•°: {r['nit']}")
        print(f"  å‡½æ•°è¯„ä¼°æ¬¡æ•°: {r['nfev']}")
        print(f"  æ¶ˆæ¯: {r['message']}")
        print("-"*50)


# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šçµæ•åº¦åˆ†æ
# ============================================================

class NLPSensitivityAnalyzer:
    """
    çµæ•åº¦åˆ†æå™¨
    
    åŠŸèƒ½ï¼š
    1. å‚æ•°çµæ•åº¦åˆ†æ
    2. çº¦æŸæ´»è·ƒæ€§åˆ†æ
    3. å½±å­ä»·æ ¼è®¡ç®—
    """
    
    def __init__(self, solver: NonlinearProgrammingSolver):
        self.solver = solver
        self.results = {}
    
    def parameter_sensitivity(self,
                              objective_builder: Callable,
                              param_name: str,
                              param_values: np.ndarray,
                              base_x0: np.ndarray,
                              bounds: List[Tuple],
                              constraints: Optional[List[Dict]] = None) -> Dict:
        """
        å‚æ•°çµæ•åº¦åˆ†æ
        
        :param objective_builder: ç»™å®šå‚æ•°è¿”å›ç›®æ ‡å‡½æ•°çš„å‡½æ•°
        :param param_name: å‚æ•°åç§°
        :param param_values: å‚æ•°å–å€¼èŒƒå›´
        :return: åˆ†æç»“æœ
        """
        print(f"\nå‚æ•°çµæ•åº¦åˆ†æ: {param_name}")
        print("-"*40)
        
        optimal_values = []
        optimal_objectives = []
        
        for param in param_values:
            obj_func = objective_builder(param)
            result = self.solver.solve(obj_func, base_x0, bounds, constraints)
            
            if result['success']:
                optimal_values.append(result['x'])
                optimal_objectives.append(result['fun'])
            else:
                optimal_values.append(None)
                optimal_objectives.append(np.nan)
        
        self.results[param_name] = {
            'param_values': param_values,
            'optimal_solutions': optimal_values,
            'optimal_objectives': optimal_objectives
        }
        
        return self.results[param_name]
    
    def plot_sensitivity(self, param_name: str, save_path: Optional[str] = None):
        """ç»˜åˆ¶çµæ•åº¦åˆ†æå›¾"""
        if param_name not in self.results:
            print(f"æœªæ‰¾åˆ°å‚æ•° {param_name} çš„åˆ†æç»“æœ")
            return
        
        data = self.results[param_name]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.plot(data['param_values'], data['optimal_objectives'],
                'o-', color=NLPPlotConfig.COLORS['optimal'],
                linewidth=2, markersize=8, label='æœ€ä¼˜ç›®æ ‡å€¼')
        
        ax.set_xlabel(param_name, fontsize=12, fontweight='bold')
        ax.set_ylabel('æœ€ä¼˜ç›®æ ‡å€¼', fontsize=12, fontweight='bold')
        ax.set_title(f'çµæ•åº¦åˆ†æ: {param_name}', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()


# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šå¯è§†åŒ–æ¨¡å—
# ============================================================

class NLPVisualizer:
    """
    éçº¿æ€§è§„åˆ’å¯è§†åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    1. ç›®æ ‡å‡½æ•°ç­‰é«˜çº¿å›¾
    2. å¯è¡ŒåŸŸå¯è§†åŒ–
    3. ä¼˜åŒ–è·¯å¾„åŠ¨ç”»
    4. ç»“æœæ±‡æ€»å›¾
    """
    
    def __init__(self, save_dir: str = './figures'):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
    
    def plot_contour_with_constraints(self,
                                      objective: Callable,
                                      bounds: List[Tuple],
                                      constraints: Optional[List[Dict]] = None,
                                      optimal_point: Optional[np.ndarray] = None,
                                      history: Optional[np.ndarray] = None,
                                      title: str = 'éçº¿æ€§è§„åˆ’é—®é¢˜',
                                      save_name: Optional[str] = None):
        """
        ç»˜åˆ¶2Dé—®é¢˜çš„ç­‰é«˜çº¿å›¾ä¸çº¦æŸ
        
        :param objective: ç›®æ ‡å‡½æ•°
        :param bounds: å˜é‡è¾¹ç•Œ
        :param constraints: çº¦æŸæ¡ä»¶
        :param optimal_point: æœ€ä¼˜è§£
        :param history: è¿­ä»£å†å²
        """
        if len(bounds) != 2:
            print("ç­‰é«˜çº¿å›¾ä»…æ”¯æŒ2ç»´é—®é¢˜")
            return
        
        x1_range = np.linspace(bounds[0][0], bounds[0][1], 100)
        x2_range = np.linspace(bounds[1][0], bounds[1][1], 100)
        X1, X2 = np.meshgrid(x1_range, x2_range)
        
        Z = np.zeros_like(X1)
        for i in range(X1.shape[0]):
            for j in range(X1.shape[1]):
                Z[i, j] = objective(np.array([X1[i, j], X2[i, j]]))
        
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # ç­‰é«˜çº¿
        contour = ax.contour(X1, X2, Z, levels=20, colors=NLPPlotConfig.COLORS['contour'], alpha=0.6)
        ax.clabel(contour, inline=True, fontsize=8)
        contourf = ax.contourf(X1, X2, Z, levels=50, cmap='viridis', alpha=0.3)
        plt.colorbar(contourf, ax=ax, label='ç›®æ ‡å‡½æ•°å€¼')
        
        # çº¦æŸè¾¹ç•Œ
        if constraints:
            for i, con in enumerate(constraints):
                C = np.zeros_like(X1)
                for ii in range(X1.shape[0]):
                    for jj in range(X1.shape[1]):
                        C[ii, jj] = con['fun'](np.array([X1[ii, jj], X2[ii, jj]]))
                
                if con['type'] == 'ineq':
                    ax.contour(X1, X2, C, levels=[0], colors=NLPPlotConfig.COLORS['constraint'],
                              linewidths=2, linestyles='--')
                    ax.contourf(X1, X2, C, levels=[0, np.inf], colors=[NLPPlotConfig.COLORS['feasible']],
                               alpha=0.1)
                elif con['type'] == 'eq':
                    ax.contour(X1, X2, C, levels=[0], colors='red', linewidths=2)
        
        # ä¼˜åŒ–è·¯å¾„
        if history is not None and len(history) > 1:
            ax.plot(history[:, 0], history[:, 1], 'o-',
                   color=NLPPlotConfig.COLORS['path'], 
                   linewidth=1.5, markersize=4, alpha=0.7, label='ä¼˜åŒ–è·¯å¾„')
        
        # æœ€ä¼˜ç‚¹
        if optimal_point is not None:
            ax.scatter(optimal_point[0], optimal_point[1],
                      c=NLPPlotConfig.COLORS['optimal'], s=200, marker='*',
                      edgecolor='white', linewidth=2, zorder=5, label='æœ€ä¼˜è§£')
        
        ax.set_xlabel('$x_1$', fontsize=12, fontweight='bold')
        ax.set_ylabel('$x_2$', fontsize=12, fontweight='bold')
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.legend(loc='upper right')
        
        plt.tight_layout()
        if save_name:
            plt.savefig(os.path.join(self.save_dir, save_name), dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_convergence(self,
                         objective: Callable,
                         history: np.ndarray,
                         title: str = 'æ”¶æ•›æ›²çº¿',
                         save_name: Optional[str] = None):
        """ç»˜åˆ¶æ”¶æ•›æ›²çº¿"""
        if history is None or len(history) == 0:
            print("æ— è¿­ä»£å†å²æ•°æ®")
            return
        
        objectives = [objective(x) for x in history]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.plot(range(len(objectives)), objectives, 'o-',
               color=NLPPlotConfig.COLORS['optimal'], linewidth=2, markersize=4)
        
        ax.set_xlabel('è¿­ä»£æ¬¡æ•°', fontsize=12, fontweight='bold')
        ax.set_ylabel('ç›®æ ‡å‡½æ•°å€¼', fontsize=12, fontweight='bold')
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # æ ‡æ³¨æœ€ä¼˜å€¼
        min_idx = np.argmin(objectives)
        ax.axhline(y=objectives[min_idx], color='red', linestyle='--', alpha=0.5)
        ax.annotate(f'æœ€ä¼˜å€¼: {objectives[min_idx]:.4f}', 
                   xy=(min_idx, objectives[min_idx]),
                   xytext=(min_idx + len(objectives)*0.1, objectives[min_idx]),
                   fontsize=10, color='red')
        
        plt.tight_layout()
        if save_name:
            plt.savefig(os.path.join(self.save_dir, save_name), dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_solution_summary(self,
                              result: Dict,
                              variable_names: Optional[List[str]] = None,
                              save_name: Optional[str] = None):
        """ç»˜åˆ¶æ±‚è§£ç»“æœæ±‡æ€»å›¾"""
        x = result['x']
        n_vars = len(x)
        
        if variable_names is None:
            variable_names = [f'$x_{i+1}$' for i in range(n_vars)]
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # å·¦å›¾ï¼šå˜é‡å–å€¼
        colors = NLPPlotConfig.COLORS
        bars = axes[0].bar(variable_names, x, color=colors['feasible'], 
                          edgecolor='white', linewidth=1.5)
        axes[0].set_ylabel('å˜é‡å€¼', fontsize=12, fontweight='bold')
        axes[0].set_title('æœ€ä¼˜è§£å„å˜é‡å–å€¼', fontsize=14, fontweight='bold')
        
        for bar, val in zip(bars, x):
            axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                        f'{val:.3f}', ha='center', va='bottom', fontsize=10)
        
        # å³å›¾ï¼šæ±‚è§£ä¿¡æ¯
        info_text = f"""
æ±‚è§£çŠ¶æ€: {'æˆåŠŸ âœ…' if result['success'] else 'å¤±è´¥ âŒ'}

æœ€ä¼˜ç›®æ ‡å€¼: {result['fun']:.6f}

è¿­ä»£æ¬¡æ•°: {result['nit']}

å‡½æ•°è¯„ä¼°æ¬¡æ•°: {result['nfev']}

æ¶ˆæ¯: {result['message']}
        """
        axes[1].text(0.1, 0.5, info_text, fontsize=12, 
                    verticalalignment='center', family='monospace',
                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))
        axes[1].axis('off')
        axes[1].set_title('æ±‚è§£ä¿¡æ¯', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        if save_name:
            plt.savefig(os.path.join(self.save_dir, save_name), dpi=300, bbox_inches='tight')
        plt.show()


# ============================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šå®Œæ•´å·¥ä½œæµ
# ============================================================

class NonlinearProgrammingPipeline:
    """
    éçº¿æ€§è§„åˆ’å®Œæ•´å·¥ä½œæµ
    
    é›†æˆæ•°æ®é¢„å¤„ç†ã€æ¨¡å‹æ±‚è§£ã€ç»“æœå¯è§†åŒ–
    """
    
    def __init__(self, verbose: bool = True, save_dir: str = './figures'):
        self.preprocessor = NLPDataPreprocessor(verbose)
        self.solver = NonlinearProgrammingSolver(verbose)
        self.visualizer = NLPVisualizer(save_dir)
        self.verbose = verbose
    
    def run(self,
            objective: Callable,
            bounds: List[Tuple],
            constraints: Optional[List[Dict]] = None,
            x0: Optional[np.ndarray] = None,
            method: str = 'SLSQP',
            multistart: bool = False,
            n_starts: int = 10,
            global_optimization: bool = False,
            plot_contour: bool = True,
            plot_convergence: bool = True,
            variable_names: Optional[List[str]] = None) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„éçº¿æ€§è§„åˆ’æ±‚è§£æµç¨‹
        
        :param objective: ç›®æ ‡å‡½æ•°
        :param bounds: å˜é‡è¾¹ç•Œ
        :param constraints: çº¦æŸæ¡ä»¶
        :param x0: åˆå§‹ç‚¹ï¼ˆå¯é€‰ï¼‰
        :param method: æ±‚è§£æ–¹æ³•
        :param multistart: æ˜¯å¦ä½¿ç”¨å¤šèµ·ç‚¹ä¼˜åŒ–
        :param n_starts: å¤šèµ·ç‚¹æ•°é‡
        :param global_optimization: æ˜¯å¦ä½¿ç”¨å…¨å±€ä¼˜åŒ–
        :param plot_contour: æ˜¯å¦ç»˜åˆ¶ç­‰é«˜çº¿å›¾ï¼ˆä»…2Dï¼‰
        :param plot_convergence: æ˜¯å¦ç»˜åˆ¶æ”¶æ•›æ›²çº¿
        :return: æ±‚è§£ç»“æœ
        """
        if self.verbose:
            print("\n" + "="*60)
            print("   éçº¿æ€§è§„åˆ’å®Œæ•´å·¥ä½œæµ")
            print("="*60)
        
        # ç”Ÿæˆåˆå§‹ç‚¹
        if x0 is None:
            x0 = self.preprocessor.generate_initial_points(bounds, 1, 'random')[0]
        
        # æ±‚è§£
        if global_optimization:
            result = self.solver.global_solve(objective, bounds, constraints)
        elif multistart:
            result = self.solver.multistart_solve(objective, bounds, n_starts, constraints, method)
        else:
            result = self.solver.solve(objective, x0, bounds, constraints, method)
        
        # å¯è§†åŒ–
        if plot_contour and len(bounds) == 2:
            self.visualizer.plot_contour_with_constraints(
                objective, bounds, constraints,
                optimal_point=result['x'],
                history=result.get('history'),
                title='éçº¿æ€§è§„åˆ’æ±‚è§£ç»“æœ'
            )
        
        if plot_convergence and result.get('history') is not None:
            self.visualizer.plot_convergence(objective, result['history'])
        
        self.visualizer.plot_solution_summary(result, variable_names)
        
        return result


# ============================================================
# ç¤ºä¾‹ï¼šæŠ•èµ„ç»„åˆä¼˜åŒ–é—®é¢˜
# ============================================================

if __name__ == "__main__":
    
    print("\n" + "="*70)
    print("   ç¤ºä¾‹ï¼šæŠ•èµ„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆé£é™©æœ€å°åŒ–ï¼‰")
    print("="*70)
    
    # é—®é¢˜æè¿°ï¼š4ç§èµ„äº§ï¼Œæœ€å°åŒ–é£é™©çš„åŒæ—¶ä¿è¯æ”¶ç›Š
    # å˜é‡ï¼šx1, x2, x3, x4 ä¸ºå„èµ„äº§æŠ•èµ„æ¯”ä¾‹
    
    # é¢„æœŸæ”¶ç›Šç‡
    expected_returns = np.array([0.12, 0.08, 0.05, 0.06])  # ç§‘æŠ€è‚¡ã€æ¶ˆè´¹è‚¡ã€å€ºåˆ¸ã€é»„é‡‘
    
    # åæ–¹å·®çŸ©é˜µï¼ˆé£é™©ç›¸å…³æ€§ï¼‰
    cov_matrix = np.array([
        [0.04, 0.01, -0.005, 0.002],
        [0.01, 0.02, 0.003, 0.001],
        [-0.005, 0.003, 0.01, -0.002],
        [0.002, 0.001, -0.002, 0.015]
    ])
    
    # ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–æŠ•èµ„ç»„åˆé£é™©ï¼ˆæ–¹å·®ï¼‰
    def portfolio_risk(x):
        return x @ cov_matrix @ x
    
    # çº¦æŸæ¡ä»¶
    constraints = [
        # æŠ•èµ„æ¯”ä¾‹å’Œä¸º1
        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
        # é¢„æœŸæ”¶ç›Šè‡³å°‘7%
        {'type': 'ineq', 'fun': lambda x: np.dot(expected_returns, x) - 0.07}
    ]
    
    # è¾¹ç•Œï¼šæ¯ç§èµ„äº§æŠ•èµ„æ¯”ä¾‹åœ¨0åˆ°1ä¹‹é—´
    bounds = [(0, 1), (0, 1), (0, 1), (0, 1)]
    
    # åˆ›å»ºå·¥ä½œæµ
    pipeline = NonlinearProgrammingPipeline(verbose=True)
    
    # æ±‚è§£
    result = pipeline.run(
        objective=portfolio_risk,
        bounds=bounds,
        constraints=constraints,
        method='SLSQP',
        multistart=True,
        n_starts=5,
        plot_contour=False,  # 4ç»´é—®é¢˜ä¸ç»˜åˆ¶ç­‰é«˜çº¿
        variable_names=['ç§‘æŠ€è‚¡', 'æ¶ˆè´¹è‚¡', 'å€ºåˆ¸', 'é»„é‡‘']
    )
    
    # è¾“å‡ºè¯¦ç»†ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“ˆ æŠ•èµ„ç»„åˆä¼˜åŒ–ç»“æœ")
    print("="*50)
    x = result['x']
    print(f"ç§‘æŠ€è‚¡æŠ•èµ„æ¯”ä¾‹: {x[0]*100:.2f}%")
    print(f"æ¶ˆè´¹è‚¡æŠ•èµ„æ¯”ä¾‹: {x[1]*100:.2f}%")
    print(f"å€ºåˆ¸æŠ•èµ„æ¯”ä¾‹:   {x[2]*100:.2f}%")
    print(f"é»„é‡‘æŠ•èµ„æ¯”ä¾‹:   {x[3]*100:.2f}%")
    print(f"\né¢„æœŸæ”¶ç›Šç‡: {np.dot(expected_returns, x)*100:.2f}%")
    print(f"æŠ•èµ„ç»„åˆé£é™©(æ ‡å‡†å·®): {np.sqrt(result['fun'])*100:.2f}%")
    print("="*50)
