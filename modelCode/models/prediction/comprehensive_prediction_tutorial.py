"""
============================================================
é¢„æµ‹æ¨¡å‹å®Œæ•´æ•™ç¨‹ (Comprehensive Prediction Tutorial)
é€‚ç”¨äºç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› (MCM/ICM)
============================================================
æœ¬æ•™ç¨‹å±•ç¤ºå¦‚ä½•å°†æ•°æ®é¢„å¤„ç†ã€é¢„æµ‹æ¨¡å‹ã€å¯è§†åŒ–å®Œæ•´ä¸²è”èµ·æ¥

åŒ…å«å†…å®¹ï¼š
1. æ•°æ®é¢„å¤„ç†æ¨¡å— (Data Preprocessing)
   - æ•°æ®åŠ è½½ä¸æ¸…æ´—
   - å¹³ç¨³æ€§æ£€éªŒ
   - æ•°æ®æ ‡å‡†åŒ–
2. é¢„æµ‹æ¨¡å‹ (Prediction Models)
   - ç§»åŠ¨å¹³å‡æ³• (Moving Average)
   - æŒ‡æ•°å¹³æ»‘æ³• (Exponential Smoothing)
   - ARIMAæ—¶é—´åºåˆ—é¢„æµ‹
   - ç°è‰²é¢„æµ‹ GM(1,1)
   - å›å½’é¢„æµ‹ (éšæœºæ£®æ—/XGBoost)
3. å¯è§†åŒ–æ¨¡å— (Visualization)
4. æ¨¡å‹è¯„ä»·ä¸å¯¹æ¯”
5. å®Œæ•´æ¡ˆä¾‹æ¼”ç¤º

ä½œè€…ï¼šMCM/ICM Team
æ—¥æœŸï¼š2026å¹´1æœˆ22æ—¥
============================================================
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
import warnings
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False
rcParams['figure.figsize'] = (12, 6)
rcParams['figure.dpi'] = 100


# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå®Œæ•´å·¥ä½œæµç¨‹æ¦‚è§ˆ
# ============================================================

def print_workflow():
    """æ‰“å°å®Œæ•´å·¥ä½œæµç¨‹"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              é¢„æµ‹æ¨¡å‹å®Œæ•´å·¥ä½œæµç¨‹ (Prediction Workflow)                   â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                                          â•‘
    â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
    â•‘   â”‚  Step 1: æ•°æ®å‡†å¤‡ (Data Preparation)                            â”‚    â•‘
    â•‘   â”‚  â”œâ”€ åŠ è½½æ—¶é—´åºåˆ—æˆ–å¤šå˜é‡æ•°æ®                                     â”‚    â•‘
    â•‘   â”‚  â”œâ”€ ç¼ºå¤±å€¼å¤„ç†ï¼ˆæ’å€¼/å¡«å……ï¼‰                                      â”‚    â•‘
    â•‘   â”‚  â””â”€ å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†                                             â”‚    â•‘
    â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
    â•‘                            â†“                                             â•‘
    â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
    â•‘   â”‚  Step 2: æ•°æ®åˆ†æ (Data Analysis)                               â”‚    â•‘
    â•‘   â”‚  â”œâ”€ å¹³ç¨³æ€§æ£€éªŒï¼ˆADFæ£€éªŒï¼‰                                        â”‚    â•‘
    â•‘   â”‚  â”œâ”€ è‡ªç›¸å…³åˆ†æï¼ˆACF/PACFå›¾ï¼‰                                     â”‚    â•‘
    â•‘   â”‚  â””â”€ è¶‹åŠ¿ä¸å­£èŠ‚æ€§åˆ†è§£                                             â”‚    â•‘
    â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
    â•‘                            â†“                                             â•‘
    â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
    â•‘   â”‚  Step 3: æ¨¡å‹é€‰æ‹©ä¸æ‹Ÿåˆ (Model Selection & Fitting)             â”‚    â•‘
    â•‘   â”‚  â”œâ”€ å°æ ·æœ¬ â†’ ç°è‰²é¢„æµ‹ GM(1,1)                                    â”‚    â•‘
    â•‘   â”‚  â”œâ”€ æ—¶é—´åºåˆ— â†’ ARIMA / æŒ‡æ•°å¹³æ»‘                                  â”‚    â•‘
    â•‘   â”‚  â””â”€ å¤šå˜é‡ â†’ å›å½’ / éšæœºæ£®æ— / XGBoost                           â”‚    â•‘
    â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
    â•‘                            â†“                                             â•‘
    â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
    â•‘   â”‚  Step 4: é¢„æµ‹ä¸è¯„ä»· (Prediction & Evaluation)                   â”‚    â•‘
    â•‘   â”‚  â”œâ”€ æ ·æœ¬å†…æ‹Ÿåˆï¼ˆIn-sample fittingï¼‰                              â”‚    â•‘
    â•‘   â”‚  â”œâ”€ æ ·æœ¬å¤–é¢„æµ‹ï¼ˆOut-of-sample forecastï¼‰                         â”‚    â•‘
    â•‘   â”‚  â””â”€ è¯„ä»·æŒ‡æ ‡ï¼ˆRMSE, MAE, MAPE, RÂ²ï¼‰                              â”‚    â•‘
    â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
    â•‘                            â†“                                             â•‘
    â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
    â•‘   â”‚  Step 5: å¯è§†åŒ–è¾“å‡º (Visualization)                             â”‚    â•‘
    â•‘   â”‚  â”œâ”€ æ‹Ÿåˆä¸é¢„æµ‹æ›²çº¿å›¾                                             â”‚    â•‘
    â•‘   â”‚  â”œâ”€ æ®‹å·®åˆ†æå›¾                                                   â”‚    â•‘
    â•‘   â”‚  â”œâ”€ ç½®ä¿¡åŒºé—´å›¾                                                   â”‚    â•‘
    â•‘   â”‚  â””â”€ å¤šæ¨¡å‹å¯¹æ¯”å›¾                                                 â”‚    â•‘
    â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
    â•‘                                                                          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†ç±»
# ============================================================

class PredictionDataPreprocessor:
    """
    é¢„æµ‹æ•°æ®é¢„å¤„ç†å™¨
    åŠŸèƒ½ï¼šæ•°æ®åŠ è½½ã€ç¼ºå¤±å€¼å¤„ç†ã€å¹³ç¨³æ€§æ£€éªŒã€æ•°æ®æ ‡å‡†åŒ–
    """
    
    def __init__(self):
        self.raw_data = None
        self.processed_data = None
        self.dates = None
        self.values = None
        self.is_stationary = None
        self.preprocessing_log = []
    
    def load_data(self, data, date_col='date', value_col='value'):
        """
        åŠ è½½æ—¶é—´åºåˆ—æ•°æ®
        
        :param data: DataFrameã€æ•°ç»„æˆ–CSVæ–‡ä»¶è·¯å¾„
        :param date_col: æ—¥æœŸåˆ—å
        :param value_col: å€¼åˆ—å
        :return: self
        """
        if isinstance(data, str):
            df = pd.read_csv(data)
            self.raw_data = df
        elif isinstance(data, pd.DataFrame):
            self.raw_data = data.copy()
        elif isinstance(data, (list, np.ndarray)):
            self.raw_data = pd.DataFrame({
                'date': pd.date_range(start='2024-01-01', periods=len(data), freq='D'),
                'value': data
            })
            date_col, value_col = 'date', 'value'
        
        if date_col in self.raw_data.columns:
            self.dates = pd.to_datetime(self.raw_data[date_col])
        else:
            self.dates = pd.date_range(start='2024-01-01', periods=len(self.raw_data), freq='D')
        
        if value_col in self.raw_data.columns:
            self.values = self.raw_data[value_col].values.astype(float)
        else:
            self.values = self.raw_data.iloc[:, -1].values.astype(float)
        
        self.processed_data = self.values.copy()
        self.preprocessing_log.append("æ•°æ®åŠ è½½å®Œæˆ")
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{len(self.values)}ä¸ªæ•°æ®ç‚¹")
        return self
    
    def generate_demo_data(self, n_periods=100, pattern='trend_seasonal', noise_level=5):
        """
        ç”Ÿæˆæ¼”ç¤ºæ•°æ®
        
        :param n_periods: æ•°æ®ç‚¹æ•°é‡
        :param pattern: æ•°æ®æ¨¡å¼ ('trend', 'seasonal', 'trend_seasonal', 'random')
        :param noise_level: å™ªå£°æ°´å¹³
        """
        np.random.seed(42)
        t = np.arange(n_periods)
        
        if pattern == 'trend':
            values = 100 + 0.5 * t + np.random.normal(0, noise_level, n_periods)
        elif pattern == 'seasonal':
            values = 100 + 15 * np.sin(2 * np.pi * t / 12) + np.random.normal(0, noise_level, n_periods)
        elif pattern == 'trend_seasonal':
            values = 100 + 0.3 * t + 15 * np.sin(2 * np.pi * t / 12) + np.random.normal(0, noise_level, n_periods)
        elif pattern == 'random':
            values = 100 + np.cumsum(np.random.normal(0, noise_level, n_periods))
        else:
            values = 100 + np.random.normal(0, noise_level, n_periods)
        
        self.dates = pd.date_range(start='2024-01-01', periods=n_periods, freq='D')
        self.values = values
        self.processed_data = values.copy()
        self.raw_data = pd.DataFrame({'date': self.dates, 'value': values})
        
        print(f"âœ… ç”Ÿæˆ{pattern}æ¨¡å¼æ¼”ç¤ºæ•°æ®ï¼š{n_periods}ä¸ªæ•°æ®ç‚¹")
        return self
    
    def handle_missing_values(self, method='interpolate'):
        """
        å¤„ç†ç¼ºå¤±å€¼
        
        :param method: 'interpolate'(æ’å€¼), 'ffill'(å‰å‘å¡«å……), 'mean'(å‡å€¼å¡«å……)
        """
        if np.isnan(self.processed_data).any():
            if method == 'interpolate':
                series = pd.Series(self.processed_data)
                self.processed_data = series.interpolate().values
            elif method == 'ffill':
                series = pd.Series(self.processed_data)
                self.processed_data = series.fillna(method='ffill').values
            elif method == 'mean':
                mean_val = np.nanmean(self.processed_data)
                self.processed_data = np.where(np.isnan(self.processed_data), mean_val, self.processed_data)
            
            self.preprocessing_log.append(f"ç¼ºå¤±å€¼å¤„ç†ï¼š{method}")
            print(f"âœ… ç¼ºå¤±å€¼å·²ä½¿ç”¨ {method} æ–¹æ³•å¤„ç†")
        else:
            print("âœ… æ— ç¼ºå¤±å€¼")
        return self
    
    def adf_test(self, significance=0.05):
        """
        ADFå¹³ç¨³æ€§æ£€éªŒ
        
        :param significance: æ˜¾è‘—æ€§æ°´å¹³
        :return: æ˜¯å¦å¹³ç¨³
        """
        try:
            from statsmodels.tsa.stattools import adfuller
            result = adfuller(self.processed_data)
            
            adf_stat = result[0]
            p_value = result[1]
            critical_values = result[4]
            
            self.is_stationary = p_value < significance
            
            print("\n" + "="*50)
            print("ğŸ“Š ADFå¹³ç¨³æ€§æ£€éªŒç»“æœ")
            print("="*50)
            print(f"  ADFç»Ÿè®¡é‡: {adf_stat:.4f}")
            print(f"  på€¼: {p_value:.4f}")
            print(f"  ä¸´ç•Œå€¼:")
            for key, val in critical_values.items():
                print(f"    {key}: {val:.4f}")
            print(f"  ç»“è®º: åºåˆ—{'å¹³ç¨³' if self.is_stationary else 'ä¸å¹³ç¨³'}")
            print("="*50)
            
            return self.is_stationary
        except ImportError:
            print("âš ï¸ éœ€è¦å®‰è£…statsmodelsåº“è¿›è¡ŒADFæ£€éªŒ")
            return None
    
    def difference(self, order=1):
        """
        å·®åˆ†å¤„ç†
        
        :param order: å·®åˆ†é˜¶æ•°
        """
        for _ in range(order):
            self.processed_data = np.diff(self.processed_data)
            self.dates = self.dates[1:]
        
        self.preprocessing_log.append(f"å·®åˆ†å¤„ç†ï¼š{order}é˜¶")
        print(f"âœ… å·²è¿›è¡Œ{order}é˜¶å·®åˆ†")
        return self
    
    def normalize(self, method='minmax'):
        """
        æ•°æ®æ ‡å‡†åŒ–
        
        :param method: 'minmax' / 'zscore'
        """
        if method == 'minmax':
            min_val = self.processed_data.min()
            max_val = self.processed_data.max()
            self.processed_data = (self.processed_data - min_val) / (max_val - min_val + 1e-10)
        elif method == 'zscore':
            mean_val = self.processed_data.mean()
            std_val = self.processed_data.std()
            self.processed_data = (self.processed_data - mean_val) / (std_val + 1e-10)
        
        self.preprocessing_log.append(f"æ•°æ®æ ‡å‡†åŒ–ï¼š{method}")
        return self
    
    def get_data(self):
        """è·å–å¤„ç†åçš„æ•°æ®"""
        return pd.DataFrame({
            'date': self.dates[:len(self.processed_data)],
            'value': self.processed_data
        })
    
    def summary(self):
        """æ‰“å°æ•°æ®æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®é¢„å¤„ç†æ‘˜è¦")
        print("="*60)
        print(f"  æ•°æ®ç‚¹æ•°é‡: {len(self.processed_data)}")
        print(f"  æ—¶é—´èŒƒå›´: {self.dates.min()} ~ {self.dates.max()}")
        print(f"  æ•°å€¼èŒƒå›´: [{self.processed_data.min():.2f}, {self.processed_data.max():.2f}]")
        print(f"  å‡å€¼: {self.processed_data.mean():.2f}")
        print(f"  æ ‡å‡†å·®: {self.processed_data.std():.2f}")
        print(f"  é¢„å¤„ç†æ­¥éª¤: {self.preprocessing_log}")
        print("="*60)


# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šé¢„æµ‹æ¨¡å‹
# ============================================================

class MovingAverageModel:
    """ç§»åŠ¨å¹³å‡é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, window=7):
        self.window = window
        self.fitted = None
        self.forecast = None
        self.metrics = None
    
    def fit_predict(self, data, n_forecast=10):
        """æ‹Ÿåˆå¹¶é¢„æµ‹"""
        values = np.array(data) if not isinstance(data, np.ndarray) else data
        n = len(values)
        
        # æ‹Ÿåˆ
        self.fitted = np.zeros(n)
        self.fitted[:self.window] = np.nan
        for t in range(self.window, n):
            self.fitted[t] = np.mean(values[t-self.window:t])
        
        # é¢„æµ‹
        self.forecast = np.zeros(n_forecast)
        last_values = list(values[-self.window:])
        for i in range(n_forecast):
            self.forecast[i] = np.mean(last_values)
            last_values.pop(0)
            last_values.append(self.forecast[i])
        
        # è¯„ä»·
        valid_idx = ~np.isnan(self.fitted)
        self.metrics = self._compute_metrics(values[valid_idx], self.fitted[valid_idx])
        
        return self
    
    def _compute_metrics(self, actual, predicted):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'RMSE': np.sqrt(mean_squared_error(actual, predicted)),
            'MAE': mean_absolute_error(actual, predicted),
            'MAPE': np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100,
            'R2': r2_score(actual, predicted)
        }
    
    def get_results(self):
        """è·å–ç»“æœ"""
        return {
            'fitted': self.fitted,
            'forecast': self.forecast,
            'metrics': self.metrics
        }


class ExponentialSmoothingModel:
    """æŒ‡æ•°å¹³æ»‘é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, alpha=0.3, beta=None, gamma=None, seasonal_period=None):
        """
        :param alpha: æ°´å¹³å¹³æ»‘ç³»æ•°
        :param beta: è¶‹åŠ¿å¹³æ»‘ç³»æ•°ï¼ˆHoltæ–¹æ³•ï¼‰
        :param gamma: å­£èŠ‚å¹³æ»‘ç³»æ•°ï¼ˆHolt-Wintersæ–¹æ³•ï¼‰
        :param seasonal_period: å­£èŠ‚å‘¨æœŸ
        """
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.seasonal_period = seasonal_period
        self.fitted = None
        self.forecast = None
        self.metrics = None
        self.method = 'simple'
        
        if beta is not None and gamma is not None:
            self.method = 'holt_winters'
        elif beta is not None:
            self.method = 'holt'
    
    def fit_predict(self, data, n_forecast=10):
        """æ‹Ÿåˆå¹¶é¢„æµ‹"""
        values = np.array(data) if not isinstance(data, np.ndarray) else data
        n = len(values)
        
        if self.method == 'simple':
            # ç®€å•æŒ‡æ•°å¹³æ»‘
            self.fitted = np.zeros(n)
            self.fitted[0] = values[0]
            for t in range(1, n):
                self.fitted[t] = self.alpha * values[t] + (1 - self.alpha) * self.fitted[t-1]
            
            # é¢„æµ‹ï¼ˆç®€å•æŒ‡æ•°å¹³æ»‘é¢„æµ‹ä¸ºå¸¸æ•°ï¼‰
            self.forecast = np.full(n_forecast, self.fitted[-1])
        
        elif self.method == 'holt':
            # HoltåŒå‚æ•°æŒ‡æ•°å¹³æ»‘
            level = np.zeros(n)
            trend = np.zeros(n)
            self.fitted = np.zeros(n)
            
            level[0] = values[0]
            trend[0] = values[1] - values[0] if n > 1 else 0
            
            for t in range(1, n):
                level[t] = self.alpha * values[t] + (1 - self.alpha) * (level[t-1] + trend[t-1])
                trend[t] = self.beta * (level[t] - level[t-1]) + (1 - self.beta) * trend[t-1]
                self.fitted[t] = level[t-1] + trend[t-1]
            
            self.fitted[0] = values[0]
            
            # é¢„æµ‹
            self.forecast = np.zeros(n_forecast)
            for h in range(n_forecast):
                self.forecast[h] = level[-1] + (h + 1) * trend[-1]
        
        elif self.method == 'holt_winters':
            # Holt-Wintersä¸‰å‚æ•°ï¼ˆåŠ æ³•æ¨¡å‹ï¼‰
            m = self.seasonal_period or 12
            
            level = np.zeros(n)
            trend = np.zeros(n)
            seasonal = np.zeros(n + n_forecast)
            self.fitted = np.zeros(n)
            
            # åˆå§‹åŒ–
            level[0] = np.mean(values[:m])
            trend[0] = (np.mean(values[m:2*m]) - np.mean(values[:m])) / m if n >= 2*m else 0
            for i in range(m):
                seasonal[i] = values[i] - level[0] if i < n else 0
            
            for t in range(1, n):
                if t >= m:
                    level[t] = self.alpha * (values[t] - seasonal[t-m]) + (1 - self.alpha) * (level[t-1] + trend[t-1])
                    trend[t] = self.beta * (level[t] - level[t-1]) + (1 - self.beta) * trend[t-1]
                    seasonal[t] = self.gamma * (values[t] - level[t]) + (1 - self.gamma) * seasonal[t-m]
                    self.fitted[t] = level[t-1] + trend[t-1] + seasonal[t-m]
                else:
                    level[t] = self.alpha * values[t] + (1 - self.alpha) * (level[t-1] + trend[t-1])
                    trend[t] = self.beta * (level[t] - level[t-1]) + (1 - self.beta) * trend[t-1]
                    self.fitted[t] = level[t-1] + trend[t-1]
            
            self.fitted[0] = values[0]
            
            # é¢„æµ‹
            self.forecast = np.zeros(n_forecast)
            for h in range(n_forecast):
                self.forecast[h] = level[-1] + (h + 1) * trend[-1] + seasonal[n - m + (h % m)]
        
        # è¯„ä»·
        valid_idx = ~np.isnan(self.fitted) & (self.fitted != 0)
        if valid_idx.sum() > 0:
            self.metrics = self._compute_metrics(values[valid_idx], self.fitted[valid_idx])
        
        return self
    
    def _compute_metrics(self, actual, predicted):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'RMSE': np.sqrt(mean_squared_error(actual, predicted)),
            'MAE': mean_absolute_error(actual, predicted),
            'MAPE': np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100,
            'R2': r2_score(actual, predicted)
        }
    
    def get_results(self):
        """è·å–ç»“æœ"""
        return {
            'fitted': self.fitted,
            'forecast': self.forecast,
            'metrics': self.metrics,
            'method': self.method
        }


class GreyPredictionModel:
    """ç°è‰²é¢„æµ‹æ¨¡å‹ GM(1,1)"""
    
    def __init__(self):
        self.a = None  # å‘å±•ç³»æ•°
        self.b = None  # ç°ä½œç”¨é‡
        self.fitted = None
        self.forecast = None
        self.metrics = None
        self.C = None  # åéªŒå·®æ¯”
        self.P = None  # å°è¯¯å·®æ¦‚ç‡
    
    def fit_predict(self, data, n_forecast=3):
        """
        æ‹Ÿåˆå¹¶é¢„æµ‹
        
        :param data: åŸå§‹æ•°æ®ï¼ˆè‡³å°‘4ä¸ªæ•°æ®ç‚¹ï¼‰
        :param n_forecast: é¢„æµ‹æ­¥æ•°
        """
        x0 = np.array(data, dtype=np.float64)
        n = len(x0)
        
        if n < 4:
            print("âš ï¸ ç°è‰²é¢„æµ‹è‡³å°‘éœ€è¦4ä¸ªæ•°æ®ç‚¹")
            return self
        
        # 1. ç´¯åŠ ç”Ÿæˆ
        x1 = np.cumsum(x0)
        
        # 2. æ„é€ çŸ©é˜µ
        B = np.zeros((n-1, 2))
        Y = np.zeros((n-1, 1))
        
        for i in range(n-1):
            B[i, 0] = -0.5 * (x1[i] + x1[i+1])
            B[i, 1] = 1
            Y[i, 0] = x0[i+1]
        
        # 3. æœ€å°äºŒä¹˜ä¼°è®¡å‚æ•°
        BT = B.T
        params = np.dot(np.dot(np.linalg.inv(np.dot(BT, B)), BT), Y)
        self.a = params[0, 0]
        self.b = params[1, 0]
        
        # 4. æ‹Ÿåˆ
        self.fitted = np.zeros(n)
        self.fitted[0] = x0[0]
        for k in range(1, n):
            x1_k = (x0[0] - self.b/self.a) * np.exp(-self.a * k) + self.b/self.a
            x1_k_1 = (x0[0] - self.b/self.a) * np.exp(-self.a * (k-1)) + self.b/self.a
            self.fitted[k] = x1_k - x1_k_1
        
        # 5. é¢„æµ‹
        self.forecast = np.zeros(n_forecast)
        for i in range(n_forecast):
            k = n + i
            x1_k = (x0[0] - self.b/self.a) * np.exp(-self.a * k) + self.b/self.a
            x1_k_1 = (x0[0] - self.b/self.a) * np.exp(-self.a * (k-1)) + self.b/self.a
            self.forecast[i] = x1_k - x1_k_1
        
        # 6. æ¨¡å‹æ£€éªŒ
        residual = x0 - self.fitted
        s1 = np.std(x0, ddof=1)
        s2 = np.std(residual, ddof=1)
        self.C = s2 / s1 if s1 != 0 else 0
        self.P = np.mean(np.abs(residual - np.mean(residual)) < 0.6745 * s1)
        
        # 7. è¯„ä»·æŒ‡æ ‡
        self.metrics = self._compute_metrics(x0, self.fitted)
        self.metrics['C'] = self.C
        self.metrics['P'] = self.P
        self.metrics['Grade'] = self._get_grade()
        
        return self
    
    def _compute_metrics(self, actual, predicted):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'RMSE': np.sqrt(mean_squared_error(actual, predicted)),
            'MAE': mean_absolute_error(actual, predicted),
            'MAPE': np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100
        }
    
    def _get_grade(self):
        """è·å–æ¨¡å‹ç²¾åº¦ç­‰çº§"""
        if self.C < 0.35 and self.P > 0.95:
            return "å¥½"
        elif self.C < 0.5 and self.P > 0.8:
            return "åˆæ ¼"
        elif self.C < 0.65 and self.P > 0.7:
            return "å‹‰å¼º"
        else:
            return "ä¸åˆæ ¼"
    
    def get_results(self):
        """è·å–ç»“æœ"""
        return {
            'fitted': self.fitted,
            'forecast': self.forecast,
            'metrics': self.metrics,
            'a': self.a,
            'b': self.b
        }


class RegressionPredictionModel:
    """å›å½’é¢„æµ‹æ¨¡å‹ï¼ˆéšæœºæ£®æ—/æ¢¯åº¦æå‡ï¼‰"""
    
    def __init__(self, model_type='random_forest', **kwargs):
        """
        :param model_type: 'random_forest' / 'gradient_boosting'
        """
        self.model_type = model_type
        self.model = None
        self.scaler = StandardScaler()
        self.fitted = None
        self.metrics = None
        self.feature_importance = None
        self.kwargs = kwargs
    
    def fit(self, X, y, test_size=0.2):
        """
        æ‹Ÿåˆæ¨¡å‹
        
        :param X: ç‰¹å¾çŸ©é˜µ
        :param y: ç›®æ ‡å˜é‡
        :param test_size: æµ‹è¯•é›†æ¯”ä¾‹
        """
        if isinstance(X, pd.DataFrame):
            self.feature_names = list(X.columns)
            X = X.values
        else:
            self.feature_names = [f"ç‰¹å¾{i+1}" for i in range(X.shape[1])]
        
        if isinstance(y, pd.Series):
            y = y.values
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # é€‰æ‹©æ¨¡å‹
        if self.model_type == 'random_forest':
            self.model = RandomForestRegressor(
                n_estimators=self.kwargs.get('n_estimators', 100),
                max_depth=self.kwargs.get('max_depth', None),
                random_state=42
            )
        elif self.model_type == 'gradient_boosting':
            self.model = GradientBoostingRegressor(
                n_estimators=self.kwargs.get('n_estimators', 100),
                learning_rate=self.kwargs.get('learning_rate', 0.1),
                random_state=42
            )
        
        # è®­ç»ƒ
        self.model.fit(X_train_scaled, y_train)
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(X_train_scaled)
        y_test_pred = self.model.predict(X_test_scaled)
        
        # è¯„ä»·
        self.metrics = {
            'train': self._compute_metrics(y_train, y_train_pred),
            'test': self._compute_metrics(y_test, y_test_pred)
        }
        
        # ç‰¹å¾é‡è¦æ€§
        if hasattr(self.model, 'feature_importances_'):
            self.feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))
        
        return self
    
    def predict(self, X):
        """é¢„æµ‹"""
        if isinstance(X, pd.DataFrame):
            X = X.values
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
    
    def _compute_metrics(self, actual, predicted):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'RMSE': np.sqrt(mean_squared_error(actual, predicted)),
            'MAE': mean_absolute_error(actual, predicted),
            'R2': r2_score(actual, predicted)
        }
    
    def get_results(self):
        """è·å–ç»“æœ"""
        return {
            'metrics': self.metrics,
            'feature_importance': self.feature_importance
        }


# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šå¯è§†åŒ–æ¨¡å—
# ============================================================

class PredictionVisualizer:
    """é¢„æµ‹å¯è§†åŒ–å™¨"""
    
    COLORS = {
        'actual': '#2E86AB',
        'fitted': '#A23B72',
        'forecast': '#F18F01',
        'confidence': '#C73E1D'
    }
    
    @staticmethod
    def plot_forecast(dates, actual, fitted, forecast, 
                      title="é¢„æµ‹ç»“æœ", confidence_interval=None, save_path=None):
        """
        ç»˜åˆ¶é¢„æµ‹ç»“æœå›¾
        
        :param dates: æ—¥æœŸåºåˆ—
        :param actual: å®é™…å€¼
        :param fitted: æ‹Ÿåˆå€¼
        :param forecast: é¢„æµ‹å€¼
        :param title: æ ‡é¢˜
        :param confidence_interval: ç½®ä¿¡åŒºé—´ (lower, upper)
        """
        fig, ax = plt.subplots(figsize=(14, 6))
        
        n = len(actual)
        n_forecast = len(forecast)
        
        # å®é™…å€¼
        ax.plot(range(n), actual, 'o-', color=PredictionVisualizer.COLORS['actual'],
               label='å®é™…å€¼', linewidth=2, markersize=4)
        
        # æ‹Ÿåˆå€¼
        valid_idx = ~np.isnan(fitted)
        ax.plot(np.where(valid_idx)[0], fitted[valid_idx], '--',
               color=PredictionVisualizer.COLORS['fitted'], label='æ‹Ÿåˆå€¼', linewidth=2)
        
        # é¢„æµ‹å€¼
        forecast_x = range(n, n + n_forecast)
        ax.plot(forecast_x, forecast, 's-', color=PredictionVisualizer.COLORS['forecast'],
               label='é¢„æµ‹å€¼', linewidth=2, markersize=6)
        
        # ç½®ä¿¡åŒºé—´
        if confidence_interval is not None:
            lower, upper = confidence_interval
            ax.fill_between(forecast_x, lower, upper, 
                          color=PredictionVisualizer.COLORS['forecast'], alpha=0.2,
                          label='95%ç½®ä¿¡åŒºé—´')
        
        ax.axvline(x=n-0.5, color='gray', linestyle='--', alpha=0.5)
        ax.set_xlabel('æ—¶é—´', fontsize=12, fontweight='bold')
        ax.set_ylabel('å€¼', fontsize=12, fontweight='bold')
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.legend(loc='best')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    @staticmethod
    def plot_residuals(actual, fitted, title="æ®‹å·®åˆ†æ", save_path=None):
        """ç»˜åˆ¶æ®‹å·®åˆ†æå›¾"""
        valid_idx = ~np.isnan(fitted)
        residuals = actual[valid_idx] - fitted[valid_idx]
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # æ®‹å·®æ—¶åºå›¾
        ax1 = axes[0, 0]
        ax1.plot(residuals, 'o-', color='#2E86AB', markersize=4)
        ax1.axhline(y=0, color='red', linestyle='--', linewidth=2)
        ax1.set_xlabel('æ—¶é—´', fontweight='bold')
        ax1.set_ylabel('æ®‹å·®', fontweight='bold')
        ax1.set_title('(a) æ®‹å·®æ—¶åºå›¾', fontweight='bold')
        ax1.grid(True, alpha=0.3)
        
        # æ®‹å·®ç›´æ–¹å›¾
        ax2 = axes[0, 1]
        ax2.hist(residuals, bins=15, color='#A23B72', edgecolor='white', density=True)
        # æ·»åŠ æ­£æ€åˆ†å¸ƒæ‹Ÿåˆæ›²çº¿
        mu, std = residuals.mean(), residuals.std()
        x = np.linspace(residuals.min(), residuals.max(), 100)
        ax2.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2, label='æ­£æ€åˆ†å¸ƒ')
        ax2.set_xlabel('æ®‹å·®', fontweight='bold')
        ax2.set_ylabel('é¢‘ç‡', fontweight='bold')
        ax2.set_title('(b) æ®‹å·®åˆ†å¸ƒ', fontweight='bold')
        ax2.legend()
        
        # Q-Qå›¾
        ax3 = axes[1, 0]
        stats.probplot(residuals, dist="norm", plot=ax3)
        ax3.set_title('(c) Q-Qå›¾', fontweight='bold')
        
        # æ®‹å·®è‡ªç›¸å…³å›¾
        ax4 = axes[1, 1]
        n = len(residuals)
        lags = min(20, n // 2)
        acf = [np.corrcoef(residuals[:-lag], residuals[lag:])[0, 1] if lag > 0 else 1 
               for lag in range(lags)]
        ax4.bar(range(lags), acf, color='#F18F01', edgecolor='white')
        ax4.axhline(y=1.96/np.sqrt(n), color='red', linestyle='--')
        ax4.axhline(y=-1.96/np.sqrt(n), color='red', linestyle='--')
        ax4.set_xlabel('æ»åé˜¶æ•°', fontweight='bold')
        ax4.set_ylabel('è‡ªç›¸å…³ç³»æ•°', fontweight='bold')
        ax4.set_title('(d) æ®‹å·®è‡ªç›¸å…³å›¾', fontweight='bold')
        
        plt.suptitle(title, fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    @staticmethod
    def plot_model_comparison(models_results, model_names, actual, title="æ¨¡å‹å¯¹æ¯”", save_path=None):
        """
        ç»˜åˆ¶å¤šæ¨¡å‹å¯¹æ¯”å›¾
        
        :param models_results: å„æ¨¡å‹ç»“æœåˆ—è¡¨
        :param model_names: æ¨¡å‹åç§°åˆ—è¡¨
        :param actual: å®é™…å€¼
        """
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6B4C9A', '#1B998B']
        
        # å­å›¾1: æ‹Ÿåˆæ›²çº¿å¯¹æ¯”
        ax1 = axes[0]
        ax1.plot(actual, 'ko-', label='å®é™…å€¼', linewidth=2, markersize=4)
        
        for i, (result, name) in enumerate(zip(models_results, model_names)):
            fitted = result.get('fitted', result.get('train_pred', None))
            if fitted is not None:
                valid_idx = ~np.isnan(fitted)
                ax1.plot(np.where(valid_idx)[0], fitted[valid_idx], '--',
                        color=colors[i % len(colors)], label=name, linewidth=2)
        
        ax1.set_xlabel('æ—¶é—´', fontweight='bold')
        ax1.set_ylabel('å€¼', fontweight='bold')
        ax1.set_title('(a) æ‹Ÿåˆæ•ˆæœå¯¹æ¯”', fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å­å›¾2: è¯„ä»·æŒ‡æ ‡å¯¹æ¯”
        ax2 = axes[1]
        metrics_names = ['RMSE', 'MAE', 'MAPE']
        x = np.arange(len(metrics_names))
        width = 0.8 / len(model_names)
        
        for i, (result, name) in enumerate(zip(models_results, model_names)):
            metrics = result.get('metrics', {})
            values = [metrics.get(m, 0) for m in metrics_names]
            ax2.bar(x + i * width, values, width, label=name, color=colors[i % len(colors)])
        
        ax2.set_xlabel('è¯„ä»·æŒ‡æ ‡', fontweight='bold')
        ax2.set_ylabel('å€¼', fontweight='bold')
        ax2.set_title('(b) è¯„ä»·æŒ‡æ ‡å¯¹æ¯”', fontweight='bold')
        ax2.set_xticks(x + width * (len(model_names) - 1) / 2)
        ax2.set_xticklabels(metrics_names)
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        
        plt.suptitle(title, fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    @staticmethod
    def plot_full_report(actual, results_dict, title="é¢„æµ‹åˆ†ææŠ¥å‘Š", save_path=None):
        """
        ç”Ÿæˆå®Œæ•´é¢„æµ‹æŠ¥å‘Š
        
        :param actual: å®é™…å€¼
        :param results_dict: åŒ…å«fitted, forecast, metricsçš„å­—å…¸
        """
        fig = plt.figure(figsize=(16, 12))
        
        fitted = results_dict.get('fitted', np.zeros_like(actual))
        forecast = results_dict.get('forecast', [])
        metrics = results_dict.get('metrics', {})
        
        n = len(actual)
        n_forecast = len(forecast) if forecast is not None else 0
        
        # å­å›¾1: é¢„æµ‹ç»“æœ
        ax1 = fig.add_subplot(2, 2, 1)
        ax1.plot(range(n), actual, 'o-', color='#2E86AB', label='å®é™…å€¼', markersize=4)
        valid_idx = ~np.isnan(fitted)
        ax1.plot(np.where(valid_idx)[0], fitted[valid_idx], '--', color='#A23B72', label='æ‹Ÿåˆå€¼')
        if n_forecast > 0:
            ax1.plot(range(n, n + n_forecast), forecast, 's-', color='#F18F01', label='é¢„æµ‹å€¼')
            ax1.axvline(x=n-0.5, color='gray', linestyle='--', alpha=0.5)
        ax1.set_xlabel('æ—¶é—´', fontweight='bold')
        ax1.set_ylabel('å€¼', fontweight='bold')
        ax1.set_title('(a) é¢„æµ‹ç»“æœ', fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å­å›¾2: è¯„ä»·æŒ‡æ ‡
        ax2 = fig.add_subplot(2, 2, 2)
        metric_names = ['RMSE', 'MAE', 'MAPE']
        metric_values = [metrics.get(m, 0) for m in metric_names]
        colors = ['#2E86AB', '#A23B72', '#F18F01']
        bars = ax2.bar(metric_names, metric_values, color=colors, edgecolor='white')
        for bar, val in zip(bars, metric_values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{val:.2f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
        ax2.set_ylabel('å€¼', fontweight='bold')
        ax2.set_title('(b) è¯„ä»·æŒ‡æ ‡', fontweight='bold')
        ax2.grid(True, alpha=0.3, axis='y')
        
        # å­å›¾3: æ®‹å·®åˆ†å¸ƒ
        ax3 = fig.add_subplot(2, 2, 3)
        residuals = actual[valid_idx] - fitted[valid_idx]
        ax3.hist(residuals, bins=15, color='#6B4C9A', edgecolor='white', density=True)
        mu, std = residuals.mean(), residuals.std()
        x = np.linspace(residuals.min(), residuals.max(), 100)
        ax3.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2)
        ax3.set_xlabel('æ®‹å·®', fontweight='bold')
        ax3.set_ylabel('é¢‘ç‡', fontweight='bold')
        ax3.set_title(f'(c) æ®‹å·®åˆ†å¸ƒ (Î¼={mu:.2f}, Ïƒ={std:.2f})', fontweight='bold')
        
        # å­å›¾4: æ‹Ÿåˆvså®é™…æ•£ç‚¹å›¾
        ax4 = fig.add_subplot(2, 2, 4)
        ax4.scatter(actual[valid_idx], fitted[valid_idx], c='#1B998B', alpha=0.6, s=50)
        # æ·»åŠ å¯¹è§’çº¿
        min_val = min(actual[valid_idx].min(), fitted[valid_idx].min())
        max_val = max(actual[valid_idx].max(), fitted[valid_idx].max())
        ax4.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='ç†æƒ³æ‹Ÿåˆçº¿')
        ax4.set_xlabel('å®é™…å€¼', fontweight='bold')
        ax4.set_ylabel('æ‹Ÿåˆå€¼', fontweight='bold')
        r2 = metrics.get('R2', r2_score(actual[valid_idx], fitted[valid_idx]))
        ax4.set_title(f'(d) æ‹Ÿåˆæ•ˆæœ (RÂ²={r2:.4f})', fontweight='bold')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.suptitle(title, fontsize=14, fontweight='bold', y=0.98)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()


# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šå®Œæ•´æ¡ˆä¾‹æ¼”ç¤º
# ============================================================

def run_complete_example():
    """è¿è¡Œå®Œæ•´çš„é¢„æµ‹æ¡ˆä¾‹"""
    
    print_workflow()
    
    print("\n" + "="*70)
    print("ğŸ¯ é¢„æµ‹æ¨¡å‹å®Œæ•´æ¡ˆä¾‹ï¼šæ—¶é—´åºåˆ—é”€é‡é¢„æµ‹")
    print("="*70)
    
    # ========================================
    # Step 1: æ•°æ®å‡†å¤‡
    # ========================================
    print("\n" + "-"*50)
    print("ğŸ“Š Step 1: æ•°æ®å‡†å¤‡")
    print("-"*50)
    
    preprocessor = PredictionDataPreprocessor()
    preprocessor.generate_demo_data(n_periods=100, pattern='trend_seasonal', noise_level=5)
    preprocessor.summary()
    
    data = preprocessor.get_data()
    actual = preprocessor.values
    
    # ========================================
    # Step 2: æ•°æ®åˆ†æ
    # ========================================
    print("\n" + "-"*50)
    print("ğŸ“Š Step 2: æ•°æ®åˆ†æ")
    print("-"*50)
    
    preprocessor.adf_test()
    
    # ========================================
    # Step 3: æ¨¡å‹æ‹Ÿåˆä¸é¢„æµ‹
    # ========================================
    print("\n" + "-"*50)
    print("ğŸ“Š Step 3: æ¨¡å‹æ‹Ÿåˆä¸é¢„æµ‹")
    print("-"*50)
    
    n_forecast = 10
    
    # 3.1 ç§»åŠ¨å¹³å‡
    print("\nã€1. ç§»åŠ¨å¹³å‡æ³•ã€‘")
    ma_model = MovingAverageModel(window=7)
    ma_model.fit_predict(actual, n_forecast=n_forecast)
    ma_results = ma_model.get_results()
    print(f"  RMSE: {ma_results['metrics']['RMSE']:.4f}")
    print(f"  MAE:  {ma_results['metrics']['MAE']:.4f}")
    print(f"  MAPE: {ma_results['metrics']['MAPE']:.2f}%")
    
    # 3.2 æŒ‡æ•°å¹³æ»‘ï¼ˆHoltæ–¹æ³•ï¼‰
    print("\nã€2. æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆHoltåŒå‚æ•°ï¼‰ã€‘")
    es_model = ExponentialSmoothingModel(alpha=0.3, beta=0.1)
    es_model.fit_predict(actual, n_forecast=n_forecast)
    es_results = es_model.get_results()
    print(f"  RMSE: {es_results['metrics']['RMSE']:.4f}")
    print(f"  MAE:  {es_results['metrics']['MAE']:.4f}")
    print(f"  MAPE: {es_results['metrics']['MAPE']:.2f}%")
    
    # 3.3 ç°è‰²é¢„æµ‹ï¼ˆä½¿ç”¨æœ€å10ä¸ªæ•°æ®ç‚¹ï¼‰
    print("\nã€3. ç°è‰²é¢„æµ‹ GM(1,1)ã€‘")
    grey_model = GreyPredictionModel()
    grey_model.fit_predict(actual[-10:], n_forecast=3)
    grey_results = grey_model.get_results()
    print(f"  å‚æ•°: a={grey_results['a']:.4f}, b={grey_results['b']:.4f}")
    print(f"  åéªŒå·®æ¯”C: {grey_results['metrics']['C']:.4f}")
    print(f"  å°è¯¯å·®æ¦‚ç‡P: {grey_results['metrics']['P']:.4f}")
    print(f"  æ¨¡å‹ç²¾åº¦ç­‰çº§: {grey_results['metrics']['Grade']}")
    
    # ========================================
    # Step 4: å¯è§†åŒ–åˆ†æ
    # ========================================
    print("\n" + "-"*50)
    print("ğŸ“Š Step 4: å¯è§†åŒ–åˆ†æ")
    print("-"*50)
    
    visualizer = PredictionVisualizer()
    
    # é¢„æµ‹ç»“æœå›¾
    visualizer.plot_forecast(
        preprocessor.dates, actual, es_results['fitted'], es_results['forecast'],
        title="æŒ‡æ•°å¹³æ»‘é¢„æµ‹ç»“æœ (Holtæ–¹æ³•)"
    )
    
    # æ®‹å·®åˆ†æ
    visualizer.plot_residuals(actual, es_results['fitted'], title="æŒ‡æ•°å¹³æ»‘æ¨¡å‹æ®‹å·®åˆ†æ")
    
    # æ¨¡å‹å¯¹æ¯”
    visualizer.plot_model_comparison(
        [ma_results, es_results],
        ['ç§»åŠ¨å¹³å‡', 'HoltæŒ‡æ•°å¹³æ»‘'],
        actual,
        title="é¢„æµ‹æ¨¡å‹å¯¹æ¯”"
    )
    
    # å®Œæ•´æŠ¥å‘Š
    visualizer.plot_full_report(actual, es_results, title="é¢„æµ‹åˆ†æå®Œæ•´æŠ¥å‘Š")
    
    # ========================================
    # ç»“è®º
    # ========================================
    print("\n" + "="*70)
    print("ğŸ† é¢„æµ‹ç»“è®º")
    print("="*70)
    
    print(f"\nç§»åŠ¨å¹³å‡æ³•: RMSE={ma_results['metrics']['RMSE']:.4f}")
    print(f"æŒ‡æ•°å¹³æ»‘æ³•: RMSE={es_results['metrics']['RMSE']:.4f}")
    
    if es_results['metrics']['RMSE'] < ma_results['metrics']['RMSE']:
        print("\nâœ… æŒ‡æ•°å¹³æ»‘æ³•è¡¨ç°æ›´å¥½ï¼Œæ¨èä½¿ç”¨")
    else:
        print("\nâœ… ç§»åŠ¨å¹³å‡æ³•è¡¨ç°æ›´å¥½ï¼Œæ¨èä½¿ç”¨")
    
    print(f"\næœªæ¥{n_forecast}æœŸé¢„æµ‹å€¼:")
    print(f"  {es_results['forecast'].round(2)}")
    
    print("\n" + "="*70)
    print("   âœ… é¢„æµ‹åˆ†æå®Œæˆï¼")
    print("="*70)
    
    return {
        'actual': actual,
        'ma_results': ma_results,
        'es_results': es_results,
        'grey_results': grey_results
    }


# ============================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šä½¿ç”¨æŒ‡å—
# ============================================================

def print_usage_guide():
    """æ‰“å°ä½¿ç”¨æŒ‡å—"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                        é¢„æµ‹æ¨¡å‹ä½¿ç”¨æŒ‡å—                                   â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                                          â•‘
    â•‘  ã€å¿«é€Ÿå¼€å§‹ã€‘                                                            â•‘
    â•‘                                                                          â•‘
    â•‘  from comprehensive_prediction_tutorial import *                         â•‘
    â•‘                                                                          â•‘
    â•‘  # 1. å‡†å¤‡æ•°æ®                                                           â•‘
    â•‘  preprocessor = PredictionDataPreprocessor()                             â•‘
    â•‘  preprocessor.load_data(your_data)  # æˆ– generate_demo_data()            â•‘
    â•‘                                                                          â•‘
    â•‘  # 2. æ•°æ®åˆ†æ                                                           â•‘
    â•‘  preprocessor.adf_test()  # å¹³ç¨³æ€§æ£€éªŒ                                   â•‘
    â•‘                                                                          â•‘
    â•‘  # 3. æ¨¡å‹é€‰æ‹©ä¸æ‹Ÿåˆ                                                     â•‘
    â•‘  model = ExponentialSmoothingModel(alpha=0.3, beta=0.1)                  â•‘
    â•‘  model.fit_predict(preprocessor.values, n_forecast=10)                   â•‘
    â•‘                                                                          â•‘
    â•‘  # 4. è·å–ç»“æœ                                                           â•‘
    â•‘  results = model.get_results()                                           â•‘
    â•‘  print(results['forecast'])  # é¢„æµ‹å€¼                                    â•‘
    â•‘  print(results['metrics'])   # è¯„ä»·æŒ‡æ ‡                                  â•‘
    â•‘                                                                          â•‘
    â•‘  # 5. å¯è§†åŒ–                                                             â•‘
    â•‘  visualizer = PredictionVisualizer()                                     â•‘
    â•‘  visualizer.plot_full_report(actual, results)                            â•‘
    â•‘                                                                          â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ã€æ¨¡å‹é€‰æ‹©å»ºè®®ã€‘                                                        â•‘
    â•‘  - æ•°æ®é‡<10: ç°è‰²é¢„æµ‹ GM(1,1)                                           â•‘
    â•‘  - æ— è¶‹åŠ¿æ— å­£èŠ‚: ç®€å•æŒ‡æ•°å¹³æ»‘                                            â•‘
    â•‘  - æœ‰è¶‹åŠ¿æ— å­£èŠ‚: HoltåŒå‚æ•° (alpha, beta)                                â•‘
    â•‘  - æœ‰è¶‹åŠ¿æœ‰å­£èŠ‚: Holt-Winters (alpha, beta, gamma)                       â•‘
    â•‘  - å¤šå˜é‡é¢„æµ‹: å›å½’æ¨¡å‹ / éšæœºæ£®æ—                                       â•‘
    â•‘                                                                          â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ã€è®ºæ–‡å›¾è¡¨å»ºè®®ã€‘                                                        â•‘
    â•‘  Figure 1: åŸå§‹æ•°æ®æ—¶åºå›¾                                                â•‘
    â•‘  Figure 2: ACF/PACFåˆ†æå›¾ï¼ˆæ—¶é—´åºåˆ—æ¨¡å‹ï¼‰                                â•‘
    â•‘  Figure 3: æ‹Ÿåˆä¸é¢„æµ‹ç»“æœå›¾                                              â•‘
    â•‘  Figure 4: æ®‹å·®åˆ†æå›¾                                                    â•‘
    â•‘  Figure 5: å¤šæ¨¡å‹å¯¹æ¯”å›¾                                                  â•‘
    â•‘                                                                          â•‘
    â•‘  Table 1: æ•°æ®æè¿°æ€§ç»Ÿè®¡                                                 â•‘
    â•‘  Table 2: æ¨¡å‹å‚æ•°                                                       â•‘
    â•‘  Table 3: é¢„æµ‹ç»“æœå¯¹æ¯”ï¼ˆRMSE, MAE, MAPEï¼‰                                â•‘
    â•‘                                                                          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


# ============================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================

if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´æ¡ˆä¾‹
    results = run_complete_example()
    
    # æ‰“å°ä½¿ç”¨æŒ‡å—
    print_usage_guide()
